/**
 * NexAI æ’ä»¶ï¼ˆå®Œç¾æ•´åˆç‰ˆï¼‰
 * å…¼å®¹ OpenAI / Gemini / Claude / ç«å±± ç­‰æ ‡å‡†æ¥å£
 * åŠŸèƒ½ï¼šå¯¹è¯ã€æœç´¢ã€è¯†å›¾ã€ç”Ÿå›¾ã€TTSã€è¯­éŸ³å›ç­”ã€å…¨å±€ Prompt é¢„è®¾ã€ä¸Šä¸‹æ–‡è®°å¿†ã€ Telegraph é•¿æ–‡ç­‰
 * ç”¨æ³•ï¼š.ai  æˆ–  .ai chat|search|image|tts|audio|searchaudio|prompt|config|model|...
 * 2025-05 æœ€ç»ˆä¼˜åŒ–ç‰ˆ
 */
import { Plugin } from "../src/utils/pluginBase.js";
import { getPrefixes } from "../src/utils/pluginManager.js";
import { Api } from "telegram";
import axios, { AxiosRequestConfig, AxiosResponse } from "axios";
import { JSONFilePreset } from "lowdb/node";
import * as path from "path";
import * as fs from "fs";
import sharp from "sharp";
import { createDirectoryInAssets } from "../src/utils/pathHelpers.js";

/* ---------- ç±»å‹å®šä¹‰ ---------- */
type Provider = {
  apiKey: string;
  baseUrl: string;
  compatauth?: Compat;
  authMethod?: AuthMethod;
  authConfig?: AuthConfig;
  fixedCompat?: Compat; // å›ºå®šå…¼å®¹ç±»å‹ï¼Œç»•è¿‡è‡ªåŠ¨æ£€æµ‹
};
type Compat = "openai" | "gemini" | "claude";
type Models = { chat: string; search: string; image: string; tts: string };
type Telegraph = {
  enabled: boolean;
  limit: number;
  token: string;
  posts: { title: string; url: string; createdAt: string }[];
};
type VoiceConfig = { gemini: string; openai: string };
type DB = {
  dataVersion?: number;
  providers: Record<string, Provider>;
  modelCompat?: Record<string, Record<string, Compat>>;
  modelCatalog?: { map: Record<string, Compat>; updatedAt?: string };
  models: Models;
  contextEnabled: boolean;
  collapse: boolean;
  telegraph: Telegraph;
  voices?: VoiceConfig;
  histories: Record<string, { role: string; content: string }[]>;
  histMeta?: Record<string, { lastAt: string }>;
  presetPrompt?: string; // å…¨å±€ Prompt é¢„è®¾
  timeout?: number; // å…¨å±€è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
  maxTokens?: number; // æœ€å¤§è¾“å‡º token æ•°
  linkPreview?: boolean; // é“¾æ¥å³æ—¶é¢„è§ˆå¼€å…³

};


/* ========== AI æ’ä»¶å¢å¼ºåŠŸèƒ½ v2.0 ========== */

/* ---------- 1. è¯·æ±‚ç¼“å­˜ç³»ç»Ÿ ---------- */
interface CacheEntry {
  content: string;
  timestamp: number;
  model: string;
  provider: string;
}

class RequestCache {
  private cache = new Map<string, CacheEntry>();
  private maxSize = 50;
  private ttl = 3 * 60 * 1000;

  private generateKey(provider: string, model: string, prompt: string): string {
    const simplePrompt = prompt.slice(0, 200).trim();
    return `${provider}:${model}:${simplePrompt}`;
  }

  get(provider: string, model: string, prompt: string): CacheEntry | null {
    const key = this.generateKey(provider, model, prompt);
    const entry = this.cache.get(key);
    if (!entry) return null;
    if (Date.now() - entry.timestamp > this.ttl) {
      this.cache.delete(key);
      return null;
    }
    return entry;
  }

  set(provider: string, model: string, prompt: string, content: string): void {
    if (this.cache.size >= this.maxSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey as string);
    }
    const key = this.generateKey(provider, model, prompt);
    this.cache.set(key, { content, timestamp: Date.now(), model, provider });
  }

  clear(): void { this.cache.clear(); }
}

const requestCache = new RequestCache();

/* ---------- 2. ä½¿ç”¨ç»Ÿè®¡ ---------- */
interface UsageStats {
  totalRequests: number;
  totalErrors: number;
  averageLatency: number;
  providerStats: Record<string, { requests: number; errors: number; avgLatency: number }>;
  lastReset: string;
}

let usageStats: UsageStats = {
  totalRequests: 0,
  totalErrors: 0,
  averageLatency: 0,
  providerStats: {},
  lastReset: new Date().toISOString()
};

const recordRequest = (provider: string, latency: number, isError: boolean) => {
  usageStats.totalRequests++;
  if (isError) usageStats.totalErrors++;
  usageStats.averageLatency = (usageStats.averageLatency * (usageStats.totalRequests - 1) + latency) / usageStats.totalRequests;
  if (!usageStats.providerStats[provider]) {
    usageStats.providerStats[provider] = { requests: 0, errors: 0, avgLatency: 0 };
  }
  const ps = usageStats.providerStats[provider];
  ps.requests++;
  if (isError) ps.errors++;
  ps.avgLatency = (ps.avgLatency * (ps.requests - 1) + latency) / ps.requests;
};

const getStatsText = (): string => {
  const rate = ((usageStats.totalRequests - usageStats.totalErrors) / Math.max(1, usageStats.totalRequests) * 100).toFixed(1);
  const lines = [
    'ğŸ“Š <b>AI ä½¿ç”¨ç»Ÿè®¡</b>', '',
    `æ€»è¯·æ±‚: ${usageStats.totalRequests} æˆåŠŸç‡: ${rate}% å¹³å‡å»¶è¿Ÿ: ${usageStats.averageLatency.toFixed(0)}ms`, '',
    '<b>æŒ‰æä¾›å•†:</b>'
  ];
  for (const [p, s] of Object.entries(usageStats.providerStats)) {
    const r = ((s.requests - s.errors) / Math.max(1, s.requests) * 100).toFixed(1);
    lines.push(`  â€¢ ${p}: ${s.requests}æ¬¡ (æˆåŠŸç‡${r}%, ${s.avgLatency.toFixed(0)}ms)`);
  }
  return lines.join('\n');
};

const resetStats = () => {  usageStats = {    totalRequests: 0,    totalErrors: 0,    averageLatency: 0,    providerStats: {},    lastReset: new Date().toISOString()  };};
/* ---------- 3. æ™ºèƒ½å›¾ç‰‡å‹ç¼© ---------- */
const smartCompressImage = async (buffer: Buffer, maxSize: number = 2 * 1024 * 1024): Promise<Buffer> => {
  if (buffer.length <= maxSize) return buffer;
  try {
    let quality = 85;
    let compressed = await sharp(buffer).jpeg({ quality }).toBuffer();
    while (compressed.length > maxSize && quality > 40) {
      quality -= 15;
      compressed = await sharp(buffer).jpeg({ quality }).toBuffer();
    }
    if (compressed.length > maxSize) {
      let width = 1920, height = 1080;
      while (compressed.length > maxSize && width > 800) {
        width = Math.floor(width * 0.8);
        height = Math.floor(height * 0.8);
        compressed = await sharp(buffer).resize(width, height, { fit: 'inside' }).jpeg({ quality: 75 }).toBuffer();
      }
    }
    return compressed;
  } catch { return buffer; }
};

/* ---------- å¸¸é‡ ---------- */
const MAX_MSG = 4096;
const PAGE_EXTRA = 48;
const WRAP_EXTRA_COLLAPSED = 64;
const HISTORY_MAX_ITEMS = 50;
const HISTORY_MAX_BYTES = 64 * 1024;
const MODEL_REFRESH_DEBOUNCE_MS = 2000;
const DEFAULT_TIMEOUT_MS = 30000; // é»˜è®¤è¶…æ—¶ 30 ç§’
const MAX_TIMEOUT_MS = 600000; // æœ€å¤§è¶…æ—¶ 10 åˆ†é’Ÿ
const DEFAULT_MAX_TOKENS = 16384; // é»˜è®¤æœ€å¤§è¾“å‡º tokenï¼ˆçº¦8000ä¸­æ–‡å­—ï¼‰
const GEMINI_VOICES = [
  "Zephyr", "Puck", "Charon", "Kore", "Fenrir", "Leda", "Orus", "Aoede",
  "Callirhoe", "Autonoe", "Enceladus", "Iapetus", "Umbriel", "Algieba",
  "Despina", "Erinome", "Algenib", "Rasalgethi", "Laomedeia", "Achernar",
  "Alnilam", "Schedar", "Gacrux", "Pulcherrima", "Achird", "Zubenelgenubi",
  "Vindemiatrix", "Sadachbia", "Sadaltager", "Sulafar"
] as const;
const OPENAI_VOICES = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"] as const;

/* ---------- å·¥å…·å‡½æ•° ---------- */
// åŠ¨æ€è·å–å‘½ä»¤å‰ç¼€
const prefixes = getPrefixes();
const mainPrefix = prefixes[0];

const trimBase = (u: string) => u.replace(/\/$/, "");
const html = (t: string) =>
  t.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;").replace(/"/g, "&quot;").replace(/'/g, "&#39;");
const escapeRegExp = (s: string) => s.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
const shortenUrlForDisplay = (u: string) => {
  try {
    const url = new URL(u);
    const host = url.hostname;
    const path = url.pathname && url.pathname !== "/" ? url.pathname : "";
    let text = host + path;
    if (text.length > 60) text = text.slice(0, 45) + "â€¦" + text.slice(-10);
    return text || u;
  } catch {
    return u.length > 60 ? u.slice(0, 45) + "â€¦" + u.slice(-10) : u;
  }
};
const nowISO = () => new Date().toISOString();
const sleep = (ms: number) => new Promise<void>(res => setTimeout(res, ms));
const shouldRetry = (err: any): boolean => {
  const s = err?.response?.status;
  const code = err?.code;
  return (
    s === 429 || s === 500 || s === 502 || s === 503 || s === 504 ||
    code === "ECONNRESET" || code === "ETIMEDOUT" || code === "ENOTFOUND" ||
    !!(err?.isAxiosError && !err?.response)
  );
};
const axiosWithRetry = async <T = any>(
  config: AxiosRequestConfig,
  tries = 2,
  backoffMs = 500
): Promise<AxiosResponse<T>> => {
  let attempt = 0;
  let lastErr: any;
  const configuredTimeout = Store.data.timeout || DEFAULT_TIMEOUT_MS;
  while (attempt <= tries) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), configuredTimeout);
    try {
      const baseConfig: AxiosRequestConfig = {
        timeout: configuredTimeout,
        signal: controller.signal,
        proxy: false,
        ...config
      };
      const result = await axios(baseConfig);
      clearTimeout(timeoutId);
      return result;
    } catch (err: any) {
      clearTimeout(timeoutId);
      lastErr = err;
      if (err.name === 'CanceledError' || err.code === 'ERR_CANCELED') {
        throw new Error(`è¯·æ±‚è¶…æ—¶ï¼ˆ${configuredTimeout / 1000}ç§’ï¼‰`);
      }
      if (attempt >= tries || !shouldRetry(err)) throw err;
      const jitter = Math.floor(Math.random() * 200);
      await sleep(backoffMs * Math.pow(2, attempt) + jitter);
      attempt++;
    }
  }
  throw lastErr;
};

/* ---------- åŸå­ JSON å†™å…¥ ---------- */
const atomicWriteJSON = async (file: string, data: any) => {
  const dir = path.dirname(file);
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
  const tmp = file + ".tmp";
  await fs.promises.writeFile(tmp, JSON.stringify(data, null, 2), "utf8");
  await fs.promises.rename(tmp, file);
};

/* ---------- é€šç”¨é‰´æƒ ---------- */
enum AuthMethod {
  BEARER_TOKEN = "bearer_token",
  API_KEY_HEADER = "api_key_header",
  QUERY_PARAM = "query_param",
  BASIC_AUTH = "basic_auth",
  CUSTOM_HEADER = "custom_header"
}
interface AuthConfig {
  method: AuthMethod;
  apiKey: string;
  headerName?: string;
  paramName?: string;
  username?: string;
  password?: string;
}
class UniversalAuthHandler {
  static buildAuthHeaders(config: AuthConfig): Record<string, string> {
    const headers: Record<string, string> = {};
    switch (config.method) {
      case AuthMethod.BEARER_TOKEN:
        headers["Authorization"] = `Bearer ${config.apiKey}`;
        break;
      case AuthMethod.API_KEY_HEADER:
        headers[config.headerName || "X-API-Key"] = config.apiKey;
        break;
      case AuthMethod.CUSTOM_HEADER:
        if (config.headerName) headers[config.headerName] = config.apiKey;
        break;
      case AuthMethod.BASIC_AUTH:
        headers["Authorization"] = `Basic ${Buffer.from(
          `${config.username || config.apiKey}:${config.password || ""}`
        ).toString("base64")}`;
        break;
    }
    return headers;
  }
  static buildAuthParams(config: AuthConfig): Record<string, string> {
    const params: Record<string, string> = {};
    if (config.method === AuthMethod.QUERY_PARAM) {
      params[config.paramName || "key"] = config.apiKey;
    }
    return params;
  }
  static detectAuthMethod(baseUrl: string): AuthMethod {
    const url = baseUrl.toLowerCase();
    if (url.includes("generativelanguage.googleapis.com") || url.includes("aiplatform.googleapis.com"))
      return AuthMethod.QUERY_PARAM;
    if (url.includes("anthropic.com")) return AuthMethod.API_KEY_HEADER;
    if (url.includes("aip.baidubce.com")) return AuthMethod.QUERY_PARAM;
    return AuthMethod.BEARER_TOKEN;
  }
}

/* ---------- ç»Ÿä¸€é‰´æƒæ„å»º ---------- */
const buildAuthAttempts = (p: Provider, extraHeaders: Record<string, string> = {}) => {
  if (p.authConfig) {
    const headers = { ...UniversalAuthHandler.buildAuthHeaders(p.authConfig), ...extraHeaders };
    const params = { ...UniversalAuthHandler.buildAuthParams(p.authConfig) };
    return [{ headers, params }];
  }
  const detected = UniversalAuthHandler.detectAuthMethod(p.baseUrl);
  const cfg: AuthConfig = {
    method: detected,
    apiKey: p.apiKey,
    headerName: detected === AuthMethod.API_KEY_HEADER ? "x-api-key" : undefined,
    paramName: detected === AuthMethod.QUERY_PARAM ? "key" : undefined
  };
  const headers = { ...UniversalAuthHandler.buildAuthHeaders(cfg), ...extraHeaders };
  const params = { ...UniversalAuthHandler.buildAuthParams(cfg) };
  return [{ headers, params }];
};
const tryPostJSON = async (url: string, body: any, attempts: Array<{ headers?: any; params?: any }>) => {
  let lastErr: any;
  for (const a of attempts) {
    try {
      const r = await axiosWithRetry({ method: "POST", url, data: body, ...(a || {}) });
      return r.data;
    } catch (err) {
      lastErr = err;
    }
  }
  throw lastErr;
};

/* ---------- lowdb å°è£… ---------- */
class Store {
  static db: any = null;
  static data: DB = {
    providers: {},
    models: { chat: "", search: "", image: "", tts: "" },
    contextEnabled: false,
    collapse: false,
    telegraph: { enabled: false, limit: 0, token: "", posts: [] },
    voices: { gemini: "Kore", openai: "alloy" },
    histories: {},
    presetPrompt: "",
    timeout: DEFAULT_TIMEOUT_MS
  };
  static baseDir = "";
  static file = "";
  static async init() {
    if (this.db) return;
    this.baseDir = createDirectoryInAssets("ai");
    this.file = path.join(this.baseDir, "config.json");
    this.db = await JSONFilePreset<DB>(this.file, this.data);
    this.data = this.db.data;
    const d: any = this.data;
    // é»˜è®¤å€¼å¡«å……
    const defaults: Record<string, any> = {
      dataVersion: 5, providers: {}, modelCompat: {}, modelCatalog: { map: {}, updatedAt: undefined },
      models: { chat: "", search: "", image: "", tts: "" }, contextEnabled: false, collapse: false,
      telegraph: { enabled: false, limit: 0, token: "", posts: [] }, voices: { gemini: "Kore", openai: "alloy" },
      histories: {}, histMeta: {}, presetPrompt: "", timeout: DEFAULT_TIMEOUT_MS, maxTokens: DEFAULT_MAX_TOKENS
    };
    for (const [k, v] of Object.entries(defaults)) if (d[k] === undefined || d[k] === null) d[k] = v;
    if (d.dataVersion < 3) { try { await refreshModelCatalog(true); } catch { } d.dataVersion = 5; }
    // ç¡®ä¿è¶…æ—¶å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if (d.timeout > MAX_TIMEOUT_MS) d.timeout = MAX_TIMEOUT_MS;
    if (d.timeout < 10000) d.timeout = DEFAULT_TIMEOUT_MS;
    await this.writeSoon();
  }
  static async write() { await atomicWriteJSON(this.file, this.data); }
  static writeSoonDelay = 300;
  static _writeTimer: NodeJS.Timeout | null = null;
  static async writeSoon(): Promise<void> {
    if (this._writeTimer) clearTimeout(this._writeTimer);
    this._writeTimer = setTimeout(async () => {
      try { await atomicWriteJSON(this.file, this.data); } finally { this._writeTimer = null; }
    }, this.writeSoonDelay);
    return Promise.resolve();
  }
}

/* ---------- æ¶ˆæ¯åˆ†ç‰‡ & æŠ˜å  ---------- */
const applyWrap = (s: string, collapse?: boolean) => {
  if (!collapse) return s;
  if (/<blockquote(?:\s|>|\/)\/?>/i.test(s)) return s;
  return `<span class="tg-spoiler">${s}</span>`;
};
const buildChunks = (text: string, collapse?: boolean, postfix?: string) => {
  const WRAP_EXTRA = collapse ? WRAP_EXTRA_COLLAPSED : 0;
  const parts = splitMessage(text, PAGE_EXTRA + WRAP_EXTRA);
  if (parts.length === 0) return [];
  if (parts.length === 1) return [applyWrap(parts[0], collapse) + (postfix || "")];
  const total = parts.length;
  const chunks: string[] = [];
  for (let i = 0; i < total; i++) {
    const isLast = i === total - 1;
    const header = `ğŸ“„ (${i + 1}/${total})\n\n`;
    const body = header + parts[i];
    const wrapped = applyWrap(body, collapse) + (isLast ? (postfix || "") : "");
    chunks.push(wrapped);
  }
  return chunks;
};
const sendLong = async (msg: Api.Message, text: string, opts?: { collapse?: boolean }, postfix?: string) => {
  const chunks = buildChunks(text, opts?.collapse, postfix);
  if (chunks.length === 0) return;
  if (chunks.length === 1) { await msg.edit({ text: chunks[0], parseMode: "html" }); return; }
  await msg.edit({ text: chunks[0], parseMode: "html" });
  if (msg.client) {
    const peer = msg.peerId;
    for (let i = 1; i < chunks.length; i++) await msg.client.sendMessage(peer, { message: chunks[i], parseMode: "html" });
  } else {
    for (let i = 1; i < chunks.length; i++) await msg.reply({ message: chunks[i], parseMode: "html" });
  }
};
const sendLongReply = async (msg: Api.Message, replyToId: number, text: string, opts?: { collapse?: boolean }, postfix?: string) => {
  const chunks = buildChunks(text, opts?.collapse, postfix);
  if (!msg.client) return;
  const peer = msg.peerId;
  for (const chunk of chunks) await msg.client.sendMessage(peer, { message: chunk, parseMode: "html", replyTo: replyToId });
};
const extractText = (m: Api.Message | null | undefined) => {
  if (!m) return "";
  const anyM: any = m;
  return (anyM.message || anyM.text || anyM.caption || "");
};
/**
 * æå–å¼•ç”¨æ–‡æœ¬æˆ–è¢«å›å¤æ¶ˆæ¯çš„æ–‡æœ¬
 * ä¼˜å…ˆçº§ï¼š1. å¼•ç”¨æ–‡æœ¬ (quoteText) 2. è¢«å›å¤æ¶ˆæ¯çš„å†…å®¹
 * @param msg å½“å‰æ¶ˆæ¯
 * @param replyMsg è¢«å›å¤çš„æ¶ˆæ¯ï¼ˆé€šè¿‡ getReplyMessage è·å–ï¼‰
 * @returns å¼•ç”¨æ–‡æœ¬æˆ–è¢«å›å¤æ¶ˆæ¯çš„æ–‡æœ¬
 */
const extractQuoteOrReplyText = (msg: Api.Message, replyMsg: Api.Message | null | undefined): string => {
  // ä¼˜å…ˆä½¿ç”¨å¼•ç”¨æ–‡æœ¬ (Telegram çš„ quote reply åŠŸèƒ½)
  const quoteText = (msg.replyTo as any)?.quoteText;
  if (quoteText && typeof quoteText === "string" && quoteText.trim()) {
    return quoteText.trim();
  }
  // å›é€€åˆ°è¢«å›å¤æ¶ˆæ¯çš„å†…å®¹
  return extractText(replyMsg);
};
const splitMessage = (text: string, reserve = 0) => {
  const limit = Math.max(1, MAX_MSG - Math.max(0, reserve));
  if (text.length <= limit) return [text];
  const parts: string[] = [];
  let cur = "";
  for (const line of text.split("\n")) {
    if (line.length > limit) {
      if (cur) { parts.push(cur); cur = ""; }
      for (let i = 0; i < line.length; i += limit) parts.push(line.slice(i, i + limit));
      continue;
    }
    const next = cur ? cur + "\n" + line : line;
    if (next.length > limit) { parts.push(cur); cur = line; } else { cur = next; }
  }
  if (cur) parts.push(cur);
  return parts;
};

/* ---------- å…¼å®¹ç±»å‹æ£€æµ‹ ---------- */
const detectCompat = (model: string): Compat => {
  const m = (model || "").toLowerCase();
  if (/\bclaude\b|anthropic/.test(m)) return "claude";
  if (/\bgemini\b|(^gemini-)|image-generation/.test(m)) return "gemini";
  if (/(^gpt-|gpt-4o|gpt-image|dall-e|^tts-1\b)/.test(m)) return "openai";
  return "openai";
};

/* ---------- æ¨¡å‹ç›®å½• ---------- */
const catalogInflight: { refreshing: boolean; lastPromise: Promise<void> | null } = { refreshing: false, lastPromise: null };
const getCompatFromCatalog = (model: string): Compat | null => {
  const ml = String(model || "").toLowerCase();
  const map = Store.data.modelCatalog?.map || ({} as Record<string, Compat>);
  const v = (map as any)[ml] as Compat | undefined;
  return v ?? null;
};
const refreshModelCatalog = async (force = false): Promise<void> => {
  if (!force && catalogInflight.refreshing) return catalogInflight.lastPromise || Promise.resolve();
  catalogInflight.refreshing = true;
  const work = (async () => {
    try {
      const entries = Object.entries(Store.data.providers || {});
      const merged: Record<string, Compat> = {};
      for (const [, p] of entries) {
        try {
          const res = await listModelsByAnyCompat(p);
          const mp: Record<string, Compat> = (((res as any).modelMap) || {}) as Record<string, Compat>;
          for (const [k, v] of Object.entries(mp)) merged[k] = v;
        } catch { }
      }
      const catalog = (Store.data.modelCatalog ??= { map: {}, updatedAt: undefined } as any);
      (catalog as any).map = merged as any;
      (catalog as any).updatedAt = nowISO();
      await Store.writeSoon();
    } finally {
      catalogInflight.refreshing = false;
      catalogInflight.lastPromise = null;
    }
  })();
  catalogInflight.lastPromise = work;
  return work;
};
/* ---------- æ¨¡å‹åˆ·æ–°é˜²æŠ– ---------- */
let refreshDebounceTimer: NodeJS.Timeout | null = null;
const debouncedRefreshModelCatalog = () => {
  if (refreshDebounceTimer) clearTimeout(refreshDebounceTimer);
  refreshDebounceTimer = setTimeout(() => {
    refreshDebounceTimer = null;
    refreshModelCatalog(true).catch(() => { });
  }, MODEL_REFRESH_DEBOUNCE_MS);
};
const compatResolving = new Map<string, Promise<Compat>>();
const resolveCompat = async (name: string, model: string, p: Provider): Promise<Compat> => {
  const ml = String(model || "").toLowerCase();
  
  // ä¼˜å…ˆä½¿ç”¨é…ç½®çš„å›ºå®šå…¼å®¹ç±»å‹
  if (p.fixedCompat) return p.fixedCompat;
  
  const cat = getCompatFromCatalog(ml);
  if (cat) return cat;
  const mc = (Store.data.modelCompat && (Store.data.modelCompat as any)[name]) ? (Store.data.modelCompat as any)[name][ml] as Compat | undefined : undefined;
  const byName = detectCompat(model);
  if (mc) return mc;
  setTimeout(() => { void refreshModelCatalog(false).catch(() => { }); }, 0);
  const pending = compatResolving.get(name + "::" + ml) || compatResolving.get(name);
  if (pending) return await pending;
  const task = (async () => {
    try {
      const res = await listModelsByAnyCompat(p);
      const primary: Compat | null = (res.compat as Compat) || null;
      const map: Record<string, Compat> = (((res as any).modelMap) || {}) as Record<string, Compat>;
      if (!Store.data.modelCompat) Store.data.modelCompat = {} as any;
      if (!(Store.data.modelCompat as any)[name]) (Store.data.modelCompat as any)[name] = {} as any;
      for (const [k, v] of Object.entries(map)) {
        const cur = (Store.data.modelCompat as any)[name][k] as Compat | undefined;
        if (cur !== v) (Store.data.modelCompat as any)[name][k] = v;
      }
      let comp: Compat = (Store.data.modelCompat as any)[name][ml] as Compat;
      if (!comp) comp = (primary as Compat) || byName;
      if (((Store.data.modelCompat as any)[name][ml] as Compat | undefined) !== comp) (Store.data.modelCompat as any)[name][ml] = comp;
      const cat = (Store.data.modelCatalog ??= { map: {}, updatedAt: undefined } as any);
      const catMap = (cat as any).map as Record<string, Compat>;
      for (const [k, v] of Object.entries(map)) if ((catMap as any)[k] !== v) (catMap as any)[k] = v as Compat;
      if ((catMap as any)[ml] !== comp) (catMap as any)[ml] = comp;
      (cat as any).updatedAt = nowISO();
      if (primary && p) if (p.compatauth !== primary) p.compatauth = primary;
      await Store.writeSoon();
      return comp;
    } catch {
      const comp: Compat = byName;
      if (!Store.data.modelCompat) Store.data.modelCompat = {} as any;
      if (!(Store.data.modelCompat as any)[name]) (Store.data.modelCompat as any)[name] = {} as any;
      if (!(Store.data.modelCompat as any)[name][ml]) (Store.data.modelCompat as any)[name][ml] = comp;
      try { await Store.writeSoon(); } catch { }
      setTimeout(() => { void refreshModelCatalog(false).catch(() => { }); }, 0);
      return comp;
    } finally {
      compatResolving.delete(name + "::" + ml);
      compatResolving.delete(name);
    }
  })();
  compatResolving.set(name + "::" + ml, task);
  return await task;
};

/* ---------- é”™è¯¯æ˜ å°„ ---------- */
const mapError = (err: any, ctx?: string): string => {
  const s = err?.response?.status as number | undefined;
  const body = err?.response?.data;
  const raw = body?.error?.message || body?.message || err?.message || String(err);
  let hint = "";
  if (s === 400) hint = "è¯·æ±‚æ ¼å¼æœ‰è¯¯ï¼Œå¯èƒ½æ˜¯æ¨¡å‹ä¸æ”¯æŒå½“å‰å‚æ•°æˆ–è¾“å…¥è¿‡é•¿";
  else if (s === 401 || s === 403) hint = "è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®ã€æ˜¯å¦æœ‰å¯¹åº”æƒé™";
  else if (s === 404) hint = "æ¥å£ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ BaseURL/å…¼å®¹ç±»å‹æˆ–æœåŠ¡å•†è·¯ç”±";
  else if (s === 429) hint = "è¯·æ±‚è¿‡äºé¢‘ç¹æˆ–é¢åº¦å—é™ï¼Œè¯·ç¨åé‡è¯•æˆ–è°ƒæ•´é€Ÿç‡";
  else if (typeof s === "number" && s >= 500) hint = "æœåŠ¡ç«¯å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•æˆ–æ›´æ¢æœåŠ¡å•†";
  else if (!s) hint = "ç½‘ç»œå¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– BaseURL";
  const where = ctx ? `ï¼ˆ${ctx}ï¼‰` : "";
  return `${raw}${hint ? "ï½œ" + hint : ""}${s ? `ï½œHTTP ${s}` : ""}${where}`;
};

/* ---------- æ¨¡å‹åè§„èŒƒåŒ– ---------- */
const normalizeModelName = (x: any): string => {
  let s = String(x?.id || x?.slug || x?.name || x || "");
  s = s.trim();
  const q = s.indexOf("?");
  if (q >= 0) s = s.slice(0, q);
  const h = s.indexOf("#");
  if (h >= 0) s = s.slice(0, h);
  if (s.includes("/")) s = s.split("/").pop() || s;
  return s.trim();
};

/* ---------- å¿«æ·é€‰å– ---------- */
const pick = (kind: keyof Models): { provider: string; model: string } | null => {
  const s = Store.data.models[kind];
  if (!s) return null;
  const i = s.indexOf(" ");
  if (i <= 0) return null;
  const provider = s.slice(0, i);
  const model = s.slice(i + 1);
  return { provider, model };
};
const providerOf = (name: string): Provider | null => Store.data.providers[name] || null;
// æ¯æ—¥ä¸€è¨€ï¼ˆåè¨€è­¦å¥ï¼‰
const dailyQuotes = [
  "ç”Ÿæ´»ä¸æ˜¯ç­‰å¾…é£æš´è¿‡å»ï¼Œè€Œæ˜¯å­¦ä¼šåœ¨é›¨ä¸­è·³èˆã€‚",
  "æ˜Ÿå…‰ä¸é—®èµ¶è·¯äººï¼Œæ—¶å…‰ä¸è´Ÿæœ‰å¿ƒäººã€‚",
  "æ„¿ä½ å‡ºèµ°åŠç”Ÿï¼Œå½’æ¥ä»æ˜¯å°‘å¹´ã€‚",
  "å±±é‡æ°´å¤ç–‘æ— è·¯ï¼ŒæŸ³æš—èŠ±æ˜åˆä¸€æ‘ã€‚",
  "æ—¢ç„¶é€‰æ‹©äº†è¿œæ–¹ï¼Œä¾¿åªé¡¾é£é›¨å…¼ç¨‹ã€‚",
  "äººç”Ÿæ²¡æœ‰ç™½èµ°çš„è·¯ï¼Œæ¯ä¸€æ­¥éƒ½ç®—æ•°ã€‚",
  "ç§ä¸€æ£µæ ‘æœ€å¥½çš„æ—¶é—´æ˜¯åå¹´å‰ï¼Œå…¶æ¬¡æ˜¯ç°åœ¨ã€‚",
  "æ„¿ä½ æ‰€å¾—çš†æ‰€æœŸï¼Œæ‰€å¤±çš†æ— ç¢ã€‚",
  "ä¸–é—´æ‰€æœ‰çš„ç›¸é‡ï¼Œéƒ½æ˜¯ä¹…åˆ«é‡é€¢ã€‚",
  "äººç”Ÿå¦‚é€†æ—…ï¼Œæˆ‘äº¦æ˜¯è¡Œäººã€‚",
  "ä¿æŒçƒ­çˆ±ï¼Œå¥”èµ´å±±æµ·ã€‚",
  "å‡¡æ˜¯è¿‡å¾€ï¼Œçš†ä¸ºåºç« ã€‚",
  "åƒé‡Œä¹‹è¡Œï¼Œå§‹äºè¶³ä¸‹ã€‚",
  "ä¸å¿˜åˆå¿ƒï¼Œæ–¹å¾—å§‹ç»ˆã€‚",
  "å¿ƒä¹‹æ‰€å‘ï¼Œç´ å±¥ä»¥å¾€ã€‚",
  "ç”Ÿå¦‚å¤èŠ±ä¹‹ç»šçƒ‚ï¼Œæ­»å¦‚ç§‹å¶ä¹‹é™ç¾ã€‚",
  "å²æœˆä¸å±…ï¼Œæ—¶èŠ‚å¦‚æµã€‚",
  "è·¯æ¼«æ¼«å…¶ä¿®è¿œå…®ï¼Œå¾å°†ä¸Šä¸‹è€Œæ±‚ç´¢ã€‚",
  "å®å‰‘é”‹ä»ç£¨ç ºå‡ºï¼Œæ¢…èŠ±é¦™è‡ªè‹¦å¯’æ¥ã€‚",
  "å¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ã€‚"
];

const footer = (model?: string, extra?: string) => {
  // éšæœºé€‰æ‹©ä¸€å¥æ¯æ—¥ä¸€è¨€
  const quote = dailyQuotes[Math.floor(Math.random() * dailyQuotes.length)];
  return "\n\n<i>ğŸ’­ æ¯æ—¥ä¸€è¨€ï¼š" + quote + "</i>";
};

// ä¿®å¤ï¼šensureDir å‡½æ•°åº”è¯¥ç‹¬ç«‹å®šä¹‰ï¼Œä¸åº”åµŒå¥—åœ¨ footer å‡½æ•°å†…éƒ¨
const ensureDir = () => {
  if (!fs.existsSync(Store.baseDir)) fs.mkdirSync(Store.baseDir, { recursive: true });
};

/* ---------- ä¸Šä¸‹æ–‡éš”ç¦»ï¼ˆç”¨æˆ·+ä¼šè¯ï¼‰ ---------- */
const contextKey = (msg: Api.Message): string => {
  const chatId = String((msg.peerId as any)?.channelId || (msg.peerId as any)?.userId || (msg.peerId as any)?.chatId || "global");
  const userId = String((msg as any).senderId || (msg as any).fromId?.userId || "unknown");
  return `${userId}:${chatId}`;
};
const chatIdStr = (msg: Api.Message) => contextKey(msg); // å…¼å®¹åˆ«å
const isGroupOrChannel = (msg: Api.Message): boolean => {
  const peer = msg.peerId;
  return (peer as any)?.className === "PeerChannel" || (peer as any)?.className === "PeerChat";
};
const histFor = (id: string) => Store.data.histories[id] || [];
const HISTORY_GLOBAL_MAX_SESSIONS = 200;
const HISTORY_GLOBAL_MAX_BYTES = 2 * 1024 * 1024;
const pruneGlobalHistories = () => {
  const ids = Object.keys(Store.data.histories || {});
  if (!ids.length) return;
  const meta = (Store.data.histMeta || {}) as Record<string, { lastAt: string }>;
  const sizeOfItem = (x: { role: string; content: string }) => Buffer.byteLength(`${x.role}:${x.content}`);
  const sizeOfHist = (arr: { role: string; content: string }[]) => arr.reduce((t, x) => t + sizeOfItem(x), 0);
  let totalBytes = 0;
  for (const id of ids) totalBytes += sizeOfHist(Store.data.histories[id] || []);
  if (ids.length <= HISTORY_GLOBAL_MAX_SESSIONS && totalBytes <= HISTORY_GLOBAL_MAX_BYTES) return;
  const sorted = ids.sort((a, b) => {
    const ta = Date.parse((meta[a]?.lastAt) || "1970-01-01T00:00:00.000Z");
    const tb = Date.parse((meta[b]?.lastAt) || "1970-01-01T00:00:00.000Z");
    return ta - tb;
  });
  while ((sorted.length > HISTORY_GLOBAL_MAX_SESSIONS || totalBytes > HISTORY_GLOBAL_MAX_BYTES) && sorted.length) {
    const victim = sorted.shift()!;
    const arr = Store.data.histories[victim] || [];
    totalBytes -= sizeOfHist(arr);
    delete Store.data.histories[victim];
    if (Store.data.histMeta) delete Store.data.histMeta[victim];
  }
};
const pushHist = (id: string, role: string, content: string) => {
  if (!Store.data.histories[id]) Store.data.histories[id] = [];
  Store.data.histories[id].push({ role, content });
  const h = Store.data.histories[id];
  while (h.length > HISTORY_MAX_ITEMS) h.shift();
  const sizeOf = (x: { role: string; content: string }) => Buffer.byteLength(`${x.role}:${x.content}`);
  let total = 0;
  for (const x of h) total += sizeOf(x);
  while (total > HISTORY_MAX_BYTES && h.length > 1) { const first = h.shift()!; total -= sizeOf(first); }
  if (!Store.data.histMeta) Store.data.histMeta = {} as any;
  (Store.data.histMeta as any)[id] = { lastAt: new Date().toISOString() };
  pruneGlobalHistories();
};

/* ---------- æ–‡æœ¬æ¸…ç† & æ ¼å¼åŒ– ---------- */
const cleanTextBasic = (t: string): string =>
  t
    .replace(/\uFEFF/g, "")
    .replace(/[\uFFFC\uFFFF\uFFFE]/g, "")
    .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]/g, "")
    .replace(/\r\n/g, "\n")
    .replace(/[\u200B\u200C\u200D\u2060]/g, "")
    .normalize("NFKC");
const escapeAndFormatForTelegram = (raw: string): string => {
  const cleaned = cleanTextBasic(raw || "");
  let escaped = html(cleaned);
  escaped = escaped.replace(/\*\*([^*]+)\*\*/g, "<b>$1</b>");
  escaped = escaped.replace(/\*\*\s*\[?å¼•ç”¨æ¥æº]?\s*\*\*/g, "<b>å¼•ç”¨æ¥æº</b>");
  escaped = escaped.replace(/^\s*-\s*\[([^]]+)]\((https?:\/\/[^\s)]+)\)\s*$/gm, (_m, title: string, url: string) => {
    const href = html(String(url));
    return `â€¢ <a href="${href}">${title}</a>`;
  });
  const urlRegex = /\bhttps?:\/\/[^\s<>"')}\x5D]+/g;
  const urls = cleaned.match(urlRegex) || [];
  for (const u of urls) {
    const display = shortenUrlForDisplay(u);
    const escapedUrl = html(u);
    const anchor = `<a href="${html(u)}">${html(display)}</a>`;
    escaped = escaped.replace(new RegExp(escapeRegExp(escapedUrl), "g"), anchor);
  }
  escaped = escaped.replace(/^&gt;\s?(.+)$/gm, "<blockquote>$1</blockquote>");
  return escaped;
};

/* ---------- è·¯ç”±é™çº§ ---------- */
const isRouteError = (err: any): boolean => {
  const s = err?.response?.status;
  const txt = String(err?.response?.data || err?.message || "").toLowerCase();
  return s === 404 || s === 405 || (s === 400 && /(unknown|not found|invalid path|no route)/.test(txt));
};
const geminiRequestWithFallback = async (p: Provider, path: string, axiosConfig: any): Promise<any> => {
  const base = trimBase(p.baseUrl);
  const mkConfigs = () => {
    const baseCfg = { ...axiosConfig };
    const headersBase = { ...(baseCfg.headers || {}) };
    const paramsBase = { ...(baseCfg.params || {}) };
    const cfgKey = { ...baseCfg, headers: { ...headersBase }, params: { ...paramsBase, key: p.apiKey } };
    const cfgXGoog = { ...baseCfg, headers: { ...headersBase, "x-goog-api-key": p.apiKey }, params: { ...paramsBase } };
    const cfgAuth = { ...baseCfg, headers: { ...headersBase, Authorization: `Bearer ${p.apiKey}` }, params: { ...paramsBase } };
    const pref = p.compatauth;
    const ordered = (pref === "openai" || pref === "claude") ? [cfgAuth, cfgXGoog, cfgKey] : [cfgKey, cfgXGoog, cfgAuth];
    const seen = new Set<string>();
    const out: any[] = [];
    for (const c of ordered) {
      const sig = JSON.stringify({ h: c.headers || {}, p: c.params || {} });
      if (!seen.has(sig)) { seen.add(sig); out.push(c); }
    }
    return out;
  };
  const configs = mkConfigs();
  const paths = [`/v1beta${path}`, `/v1${path}`];
  let lastErr: any;
  for (const suffix of paths) {
    for (const cfg of configs) {
      try {
        const r = await axiosWithRetry({ url: base + suffix, ...cfg });
        return r.data;
      } catch (err: any) {
        lastErr = err;
        if (isRouteError(err)) break;
      }
    }
  }
  throw lastErr;
};

/* ---------- Anthropic ç‰ˆæœ¬ç¼“å­˜ ---------- */
const anthropicVersionCache = new Map<string, string>();
const getAnthropicVersion = async (p: Provider): Promise<string> => {
  const key = trimBase(p.baseUrl) || "anthropic";
  const cached = anthropicVersionCache.get(key);
  if (cached) return cached;
  let ver = "2023-06-01";
  const base = trimBase(p.baseUrl);
  try {
    await axiosWithRetry({ method: "GET", url: base + "/v1/models", headers: { "x-api-key": p.apiKey } });
  } catch (err: any) {
    const txt = JSON.stringify(err?.response?.data || err?.message || "");
    const matches = txt.match(/\b20\d{2}-\d{2}-\d{2}\b/g);
    if (matches && matches.length) {
      matches.sort();
      ver = matches[matches.length - 1];
    }
  }
  anthropicVersionCache.set(key, ver);
  return ver;
};

/* ---------- AI å“åº”æ¸…ç†å·¥å…· ---------- */

/**
 * æ¸…ç† AI æ€è€ƒæ ‡ç­¾ï¼ˆ<think>...</think>ï¼‰
 * ä¸€äº›æ¨¡å‹ä¼šè¿”å›å¸¦æœ‰æ€è€ƒè¿‡ç¨‹çš„å“åº”ï¼Œéœ€è¦ç§»é™¤
 */
const cleanAIThinking = (text: string): string => {
  // ç§»é™¤ <think>...</think> æ ‡ç­¾åŠå…¶å†…å®¹
  let cleaned = text.replace(/<think>[\s\S]*?<\/think>/gi, "");
  // åŒæ—¶å¤„ç† [think]...[/think] æ ¼å¼
  cleaned = cleaned.replace(/\[think\][\s\S]*?\[\/think\]/gi, "");
  return cleaned.trim();
};

/**
 * ä»æ–‡æœ¬ä¸­æå–å†…åµŒçš„ base64 å›¾ç‰‡
 * æ”¯æŒ Markdown å›¾ç‰‡æ ¼å¼ï¼š![alt](data:image/...;base64,...)
 * ä»¥åŠç›´æ¥çš„ data URI æ ¼å¼
 * @returns æå–çš„å›¾ç‰‡æ•°ç»„ï¼ŒåŒ…å« base64 æ•°æ®å’Œ mime ç±»å‹
 */
const extractEmbeddedImages = (text: string): Array<{ data: string; mime: string; alt?: string }> => {
  const images: Array<{ data: string; mime: string; alt?: string }> = [];

  // åŒ¹é… Markdown æ ¼å¼: ![alt](data:image/xxx;base64,...)
  const mdRegex = /!\[([^\]]*)\]\((data:image\/([a-z0-9+.-]+);base64,([A-Za-z0-9+/=]+))\)/gi;
  let match: RegExpExecArray | null;
  while ((match = mdRegex.exec(text)) !== null) {
    const alt = match[1];
    const mimeType = match[3]; // jpeg, png, webp, etc.
    const base64Data = match[4];
    if (base64Data && base64Data.length > 100) { // ç¡®ä¿æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ•°æ®
      images.push({ data: base64Data, mime: `image/${mimeType}`, alt });
    }
  }

  // åŒ¹é…ç›´æ¥çš„ data URI æ ¼å¼ï¼ˆä¸åœ¨ Markdown ä¸­ï¼‰
  // é¿å…é‡å¤åŒ¹é…å·²ç»åœ¨ Markdown ä¸­å¤„ç†è¿‡çš„
  const dataUriRegex = /(?<!![\^\[\]\(])data:image\/([a-z0-9+.-]+);base64,([A-Za-z0-9+/=]{100,})/gi;
  while ((match = dataUriRegex.exec(text)) !== null) {
    const mimeType = match[1];
    const base64Data = match[2];
    // æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡ï¼ˆé€šè¿‡æ¯”è¾ƒbase64æ•°æ®çš„å‰100ä¸ªå­—ç¬¦ï¼‰
    const isDuplicate = images.some(img => img.data.substring(0, 100) === base64Data.substring(0, 100));
    if (!isDuplicate && base64Data.length > 100) {
      images.push({ data: base64Data, mime: `image/${mimeType}` });
    }
  }

  return images;
};

/**
 * ä»æ–‡æœ¬ä¸­ç§»é™¤å†…åµŒå›¾ç‰‡ï¼Œåªä¿ç•™æ–‡å­—å†…å®¹
 */
const cleanEmbeddedImages = (text: string): string => {
  // ç§»é™¤ Markdown å›¾ç‰‡æ ¼å¼
  let cleaned = text.replace(/!\[[^\]]*\]\(data:image\/[a-z0-9+.-]+;base64,[A-Za-z0-9+/=]+\)/gi, "[å›¾ç‰‡]");
  // ç§»é™¤ç›´æ¥çš„ data URI
  cleaned = cleaned.replace(/data:image\/[a-z0-9+.-]+;base64,[A-Za-z0-9+/=]{100,}/gi, "[å›¾ç‰‡æ•°æ®]");
  return cleaned.trim();
};

/**
 * å¤„ç† AI å“åº”ï¼Œæå–å›¾ç‰‡å’Œæ¸…ç†æ–‡æœ¬
 * @returns å¤„ç†åçš„ç»“æœï¼ŒåŒ…å«æ¸…ç†åçš„æ–‡æœ¬å’Œæå–çš„å›¾ç‰‡
 */
const processAIResponse = (rawContent: string): { text: string; images: Array<{ data: string; mime: string; alt?: string }> } => {
  // é¦–å…ˆæ¸…ç†æ€è€ƒæ ‡ç­¾
  const withoutThinking = cleanAIThinking(rawContent);

  // æå–å†…åµŒå›¾ç‰‡
  const images = extractEmbeddedImages(withoutThinking);

  // æ¸…ç†å›¾ç‰‡æ•°æ®ï¼Œåªä¿ç•™æ–‡å­—
  let text = withoutThinking;
  if (images.length > 0) {
    text = cleanEmbeddedImages(withoutThinking);
  }

  return { text, images };
};

/* ---------- æ ¼å¼åŒ– Q&A ---------- */
const formatQA = (qRaw: string, aRaw: string) => {
  const expandAttr = Store.data.collapse ? ' expandable' : "";
  const qEsc = escapeAndFormatForTelegram(qRaw);
  const aEsc = escapeAndFormatForTelegram(aRaw);
  const Q = `<b>Q:</b>\n<blockquote${expandAttr}>${qEsc}</blockquote>`;
  const A = `<b>A:</b>\n<blockquote${expandAttr}>${aEsc}</blockquote>`;
  return `${Q}\n\n${A}`;
};

/* ---------- Telegraph å·¥å…· ---------- */
const toNodes = (text: string) => JSON.stringify(text.split("\n\n").map(p => ({ tag: "p", children: [p] })));
const ensureTGToken = async (): Promise<string> => {
  if (Store.data.telegraph.token) return Store.data.telegraph.token;
  const resp = await axiosWithRetry({
    method: "POST",
    url: "https://api.telegra.ph/createAccount",
    params: { short_name: "NexAI", author_name: "NexBot" }
  });
  const t = resp.data?.result?.access_token || "";
  Store.data.telegraph.token = t;
  await Store.writeSoon();
  return t;
};
const createTGPage = async (title: string, text: string): Promise<string[]> => {
  // Telegraph å•é¡µé™åˆ¶çº¦ 64KB JSONï¼Œ8000å®‰å…¨å€¼
  const MAX_CHARS_PER_PAGE = 8000;

  const tryCreate = async (token: string, pageTitle: string, content: string): Promise<string | null> => {
    const contentNodes = JSON.parse(toNodes(content));
    const resp = await axiosWithRetry({
      method: "POST",
      url: "https://api.telegra.ph/createPage",
      headers: { "Content-Type": "application/json" },
      data: {
        access_token: token,
        title: pageTitle,
        content: contentNodes,
        return_content: false
      }
    });
    if (!resp.data?.ok) {
      return null;
    }
    return resp.data?.result?.url || null;
  };

  // æŒ‰æ®µè½åˆ†å‰²å†…å®¹æˆå¤šä¸ªå—
  const splitContent = (fullText: string): string[] => {
    if (fullText.length <= MAX_CHARS_PER_PAGE) return [fullText];

    const paragraphs = fullText.split("\n\n");
    const chunks: string[] = [];
    let current = "";

    for (const para of paragraphs) {
      const next = current ? current + "\n\n" + para : para;
      if (next.length > MAX_CHARS_PER_PAGE && current) {
        chunks.push(current);
        current = para;
      } else {
        current = next;
      }
    }
    if (current) chunks.push(current);
    return chunks;
  };

  try {
    const token = await ensureTGToken();
    if (!token) return [];

    const chunks = splitContent(text);



    // å¤šé¡µåˆ›å»º
    const urls: string[] = [];
    for (let i = 0; i < chunks.length; i++) {
      const pageTitle = title;
      try {
        const url = await tryCreate(token, pageTitle, chunks[i]);
        if (url) urls.push(url);
      } catch {
        // é¡µé¢åˆ›å»ºå¤±è´¥ï¼Œé™é»˜å¤„ç†
      }
    }
    return urls;
  } catch {
    return [];
  }
};


/* ---------- åª’ä½“å¤„ç†è¾…åŠ©å‡½æ•° ---------- */

// å½’ä¸€åŒ–ä¸‹è½½çš„åª’ä½“ç»“æœ
const normalizeDownloadedMedia = async (downloaded: any): Promise<Buffer | null> => {
  if (!downloaded) return null;
  if (Buffer.isBuffer(downloaded)) return downloaded;
  if (typeof downloaded === "string" && downloaded.length > 0) {
    try {
      const stat = await fs.promises.stat(downloaded);
      if (!stat.isFile()) return null;
      return await fs.promises.readFile(downloaded);
    } catch {
      return null;
    }
  }
  return null;
};

// æå–ç¬¬ä¸€å¸§ (GIF/WebM/Sticker)
const extractFirstFrame = async (buffer: Buffer): Promise<Buffer | null> => {
  try {
    // animated: true è¯»å–ç¬¬ä¸€å¸§ï¼Œè½¬ä¸º png
    return await sharp(buffer, { animated: true }).png().toBuffer();
  } catch {
    return null;
  }
};

// è·å– Document ç¼©ç•¥å›¾
const getDocumentThumb = (doc: Api.Document): Api.TypePhotoSize | undefined => {
  const thumbs = doc.thumbs || [];
  if (thumbs.length === 0) return undefined;
  return thumbs[thumbs.length - 1];
};

/**
 * æ™ºèƒ½ä¸‹è½½å¹¶å¤„ç†æ¶ˆæ¯ä¸­çš„åª’ä½“ï¼ˆæ”¯æŒå›¾ç‰‡ã€GIFã€è´´çº¸ç­‰ï¼‰
 * è¿”å›é€‚åˆ AI è§†è§‰æ¨¡å‹çš„ Buffer (é€šå¸¸æ˜¯ PNG/JPEG)
 */
const downloadMessageMediaAsData = async (msg: Api.Message): Promise<{ buffer: Buffer; mime: string } | null> => {
  if (!msg?.media || !msg.client) return null;

  // 1. æ™®é€š Photo
  if (msg.media instanceof Api.MessageMediaPhoto) {
    const downloaded = await msg.client.downloadMedia(msg);
    const buffer = await normalizeDownloadedMedia(downloaded);
    if (!buffer) return null;
    return { buffer, mime: "image/jpeg" };
  }

  // 2. Document (å¯èƒ½æ˜¯æ™®é€šå›¾ç‰‡ã€GIFã€è´´çº¸)
  if (msg.media instanceof Api.MessageMediaDocument && msg.media.document instanceof Api.Document) {
    const doc = msg.media.document;
    const docMime = (doc.mimeType || "").toLowerCase();
    const isAnimated =
      docMime === "image/gif" ||
      docMime === "video/webm" ||
      docMime === "application/x-tgsticker" ||
      docMime === "application/x-tg-sticker" ||
      doc.attributes?.some((attr) => attr instanceof Api.DocumentAttributeAnimated);

    // 2.1 é™æ€å›¾ç‰‡ Document
    if (!isAnimated && docMime.startsWith("image/")) {
      const downloaded = await msg.client.downloadMedia(msg);
      const buffer = await normalizeDownloadedMedia(downloaded);
      if (!buffer) return null;
      return { buffer, mime: docMime };
    }

    // 2.2 åŠ¨æ€åª’ä½“ (GIF / WebM / Sticker) -> æŠ½å¸§
    let frameBuffer: Buffer | null = null;

    // ä¼˜å…ˆå°è¯•åˆ©ç”¨ Telegram æä¾›çš„ç¼©ç•¥å›¾
    const thumb = getDocumentThumb(doc);
    if (thumb) {
      try {
        const downloaded = await msg.client.downloadMedia(msg, { thumb });
        const buffer = await normalizeDownloadedMedia(downloaded);
        if (buffer) {
          // ç¡®ä¿æ˜¯ PNG
          try { frameBuffer = await sharp(buffer).png().toBuffer(); } catch { frameBuffer = buffer; }
        }
      } catch {
        // ç¼©ç•¥å›¾ä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ°åŸæ–‡ä»¶
      }
    }

    // å¦‚æœæ²¡æœ‰ç¼©ç•¥å›¾æˆ–å¤±è´¥ï¼Œå°è¯•ä¸‹è½½åŸæ–‡ä»¶å¹¶æŠ½å¸§
    if (!frameBuffer) {
      try {
        const downloaded = await msg.client.downloadMedia(msg);
        const buffer = await normalizeDownloadedMedia(downloaded);
        if (buffer) {
          frameBuffer = await extractFirstFrame(buffer);
        }
      } catch {
        // åŸæ–‡ä»¶ä¸‹è½½/æŠ½å¸§å¤±è´¥
      }
    }

    if (frameBuffer) {
      return { buffer: frameBuffer, mime: "image/png" };
    }
  }

  return null;
};

/* ---------- èŠå¤©é€‚é… ---------- */
const chatOpenAI = async (p: Provider, model: string, msgs: { role: string; content: string }[], maxTokens?: number, useSearch?: boolean) => {
  const url = trimBase(p.baseUrl) + "/v1/chat/completions";
  const effectiveMaxTokens = maxTokens || Store.data.maxTokens || DEFAULT_MAX_TOKENS;
  const body: any = { model, messages: msgs, max_tokens: effectiveMaxTokens };
  if (useSearch && p.baseUrl?.includes("api.openai.com")) {
    body.tools = [{
      type: "function",
      function: {
        name: "web_search",
        description: "è”ç½‘æœç´¢å½“å‰ä¿¡æ¯å¹¶è¿”å›ç›¸å…³ç»“æœ",
        parameters: {
          type: "object",
          properties: { query: { type: "string", description: "æœç´¢å…³é”®è¯" } },
          required: ["query"]
        }
      }
    }];
  } else if (useSearch) {
    const searchPrompt = "è¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¦‚æœéœ€è¦æœ€æ–°ä¿¡æ¯è¯·è¯´æ˜ã€‚";
    msgs[msgs.length - 1].content = searchPrompt + "\n\n" + msgs[msgs.length - 1].content;
  }
  const attempts = buildAuthAttempts(p);
  try {
    const data: any = await tryPostJSON(url, body, attempts);
    return data?.choices?.[0]?.message?.content || "";
  } catch (lastErr: any) {
    const status = lastErr?.response?.status;
    const bodyErr = lastErr?.response?.data;
    const msg = bodyErr?.error?.message || bodyErr?.message || lastErr?.message || String(lastErr);
    throw new Error(`[chatOpenAI] adapter=openai model=${html(model)} status=${status || "network"} message=${msg}`);
  }
};
const chatClaude = async (p: Provider, model: string, msgs: { role: string; content: string }[], maxTokens?: number, useSearch?: boolean) => {
  const url = trimBase(p.baseUrl) + "/v1/messages";
  const effectiveMaxTokens = maxTokens || Store.data.maxTokens || DEFAULT_MAX_TOKENS;
  const body: any = { model, max_tokens: effectiveMaxTokens, messages: msgs.map(m => ({ role: m.role === "assistant" ? "assistant" : "user", content: m.content })) };
  if (useSearch && p.baseUrl?.includes("api.anthropic.com")) {
    body.tools = [{ type: "web_search_20241220", name: "web_search", max_uses: 3 }];
  }
  const v = await getAnthropicVersion(p);
  const attempts = buildAuthAttempts(p, { "anthropic-version": v });
  try {
    const data: any = await tryPostJSON(url, body, attempts);
    if (data?.content && Array.isArray(data.content)) {
      const textBlocks = data.content
        .filter((block: any) => block.type === "text")
        .map((block: any) => block.text)
        .filter((text: string) => text && text.trim());
      if (textBlocks.length > 0) return textBlocks.join("\n\n");
    }
    const possibleTexts = [
      data?.content?.[0]?.text,
      data?.message?.content?.[0]?.text,
      data?.choices?.[0]?.message?.content,
      data?.response,
      data?.text,
      data?.content,
      data?.message?.content,
      data?.output
    ];
    for (const text of possibleTexts) if (typeof text === "string" && text.trim()) return text.trim();
    return "";
  } catch (lastErr: any) {
    const status = lastErr?.response?.status;
    const bodyErr = lastErr?.response?.data;
    const msg = bodyErr?.error?.message || bodyErr?.message || lastErr?.message || String(lastErr);
    throw new Error(`[chatClaude] adapter=claude model=${html(model)} status=${status || "network"} message=${msg}`);
  }
};
const chatGemini = async (p: Provider, model: string, msgs: { role: string; content: string }[], useSearch: boolean = false) => {
  const path = `/models/${encodeURIComponent(model)}:generateContent`;
  const effectiveMaxTokens = Store.data.maxTokens || DEFAULT_MAX_TOKENS;
  const requestData: any = {
    contents: [{ parts: msgs.map(m => ({ text: m.content })) }],
    generationConfig: {
      maxOutputTokens: effectiveMaxTokens,
      temperature: 0.9
    }
  };
  if (useSearch) requestData.tools = [{ googleSearch: {} }];
  const data = await geminiRequestWithFallback(p, path, {
    method: "POST",
    data: requestData,
    params: { key: p.apiKey }
  });
  const parts = data?.candidates?.[0]?.content?.parts || [];
  return parts.map((x: any) => x.text || "").join("");
};

/* ---------- è§†è§‰å¯¹è¯ ---------- */
const chatVisionOpenAI = async (p: Provider, model: string, imageB64: string, prompt?: string, mime?: string) => {
  const url = trimBase(p.baseUrl) + "/v1/chat/completions";
  const content = [
    { type: "text", text: prompt || "ç”¨ä¸­æ–‡æè¿°æ­¤å›¾ç‰‡" },
    { type: "image_url", image_url: { url: `data:${mime || "image/png"};base64,${imageB64}` } }
  ];
  const body = { model, messages: [{ role: "user", content }] };
  const attempts = buildAuthAttempts(p);
  try {
    const data: any = await tryPostJSON(url, body, attempts);
    return data?.choices?.[0]?.message?.content || "";
  } catch (lastErr: any) {
    const status = lastErr?.response?.status;
    const bodyErr = lastErr?.response?.data;
    const msg = bodyErr?.error?.message || bodyErr?.message || lastErr?.message || String(lastErr);
    throw new Error(`[chatVisionOpenAI] adapter=openai model=${html(model)} status=${status || "network"} message=${msg}`);
  }
};
const chatVisionGemini = async (p: Provider, model: string, imageB64: string, prompt?: string, mime?: string) => {
  const path = `/models/${encodeURIComponent(model)}:generateContent`;
  try {
    const data = await geminiRequestWithFallback(p, path, {
      method: "POST",
      data: {
        contents: [
          {
            role: "user",
            parts: [
              { inlineData: { mimeType: mime || "image/png", data: imageB64 } },
              { text: prompt || "ç”¨ä¸­æ–‡æè¿°æ­¤å›¾ç‰‡" }
            ]
          }
        ]
      },
      params: { key: p.apiKey }
    });
    const parts = data?.candidates?.[0]?.content?.parts || [];
    return parts.map((x: any) => x.text || "").join("");
  } catch (err: any) {
    const status = err?.response?.status;
    const body = err?.response?.data;
    const msg = body?.error?.message || body?.message || err?.message || String(err);
    throw new Error(`[chatVisionGemini] adapter=gemini model=${html(model)} status=${status || "network"} message=${msg}`);
  }
};
const chatVisionClaude = async (p: Provider, model: string, imageB64: string, prompt?: string, mime?: string) => {
  const url = trimBase(p.baseUrl) + "/v1/messages";
  const v = await getAnthropicVersion(p);
  const body = {
    model,
    max_tokens: 1024,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt || "ç”¨ä¸­æ–‡æè¿°æ­¤å›¾ç‰‡" },
          { type: "image", source: { type: "base64", media_type: mime || "image/png", data: imageB64 } }
        ]
      }
    ]
  };
  const attempts = buildAuthAttempts(p, { "anthropic-version": v });
  try {
    const data: any = await tryPostJSON(url, body, attempts);
    const blocks = data?.content || data?.message?.content || [];
    return Array.isArray(blocks) ? blocks.map((b: any) => b?.text || b?.content?.[0]?.text || "").join("") : "";
  } catch (lastErr: any) {
    const status = lastErr?.response?.status;
    const bodyErr = lastErr?.response?.data;
    const msg = bodyErr?.error?.message || bodyErr?.message || lastErr?.message || String(lastErr);
    throw new Error(`[chatVisionClaude] adapter=claude model=${html(model)} status=${status || "network"} message=${msg}`);
  }
};
const chatVision = async (p: Provider, compat: string, model: string, imageB64: string, prompt?: string, mime?: string): Promise<string> => {
  if (compat === "openai") return chatVisionOpenAI(p, model, imageB64, prompt, mime);
  if (compat === "gemini") return chatVisionGemini(p, model, imageB64, prompt, mime);
  if (compat === "claude") return chatVisionClaude(p, model, imageB64, prompt, mime);
  return chatOpenAI(p, model, [{ role: "user", content: prompt || "æè¿°è¿™å¼ å›¾ç‰‡" } as any] as any);
};

/* ---------- ç”Ÿå›¾ ---------- */
const imageOpenAI = async (
  p: Provider,
  model: string,
  prompt: string,
  sourceImage?: { data: string; mime: string }
): Promise<string> => {
  const base = trimBase(p.baseUrl);
  const isEdit = !!sourceImage;

  // å°è¯•å¤šç§æ–¹å¼ï¼šä¼˜å…ˆä½¿ç”¨ generations ç«¯ç‚¹ï¼ˆå¤§å¤šæ•°ç¬¬ä¸‰æ–¹å…¼å®¹ï¼‰
  // å¦‚æœæœ‰æºå›¾ç‰‡ï¼Œå°†å›¾ç‰‡ base64 åµŒå…¥è¯·æ±‚ä½“ï¼ˆæŸäº›å¹³å°å¦‚è±†åŒ…æ”¯æŒæ­¤æ–¹å¼ï¼‰
  const url = base + "/v1/images/generations";

  // æ ¹æ®æ¨¡å‹é€‰æ‹©åˆé€‚çš„åˆ†è¾¨ç‡
  // æŸäº›æ¨¡å‹ï¼ˆå¦‚è±†åŒ… imagenï¼‰è¦æ±‚æœ€å° 3686400 åƒç´  (1920x1920)
  // é€šç”¨æ¨¡å‹ä½¿ç”¨ 1024x1024
  const modelLower = model.toLowerCase();
  const needsHighRes = modelLower.includes("imagen") ||
    modelLower.includes("sd3") ||
    modelLower.includes("sdxl") ||
    modelLower.includes("flux") ||
    modelLower.includes("seedream") ||
    modelLower.includes("doubao");
  const imageSize = needsHighRes ? "2048x2048" : "1024x1024";

  // æ„å»ºè¯·æ±‚ä½“
  let body: any = {
    model,
    prompt,
    n: 1,
    response_format: "b64_json",
    size: imageSize
  };

  // å¦‚æœæœ‰æºå›¾ç‰‡ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä½“ï¼ˆå…¼å®¹æŸäº›æ”¯æŒå›¾ç”Ÿå›¾çš„ç¬¬ä¸‰æ–¹å¹³å°ï¼‰
  if (isEdit && sourceImage) {
    body.image = `data:${sourceImage.mime};base64,${sourceImage.data}`;
  }

  const attempts = buildAuthAttempts(p, { "Content-Type": "application/json" });

  try {
    const data = await tryPostJSON(url, body, attempts);
    const first = data?.data?.[0] || {};
    const b64 = first?.b64_json || first?.image_base64 || first?.image || "";
    if (b64) return String(b64);
    const urlOut = first?.url || first?.image_url;
    if (urlOut) {
      try {
        const r = await axiosWithRetry({ method: "GET", url: String(urlOut), responseType: "arraybuffer" });
        const buf: any = r.data;
        const b: Buffer = Buffer.isBuffer(buf) ? buf : Buffer.from(buf);
        if (b && b.length > 0) return b.toString("base64");
      } catch { }
    }
    return "";
  } catch (err: any) {
    // å¦‚æœ generations ç«¯ç‚¹ä¸æ”¯æŒå›¾ç”Ÿå›¾ï¼Œå°è¯• edits ç«¯ç‚¹ (æ ‡å‡† OpenAI æ ¼å¼)
    if (isEdit && sourceImage) {
      try {
        const editUrl = base + "/v1/images/edits";
        const editBody = {
          model,
          prompt,
          image: `data:${sourceImage.mime};base64,${sourceImage.data}`,
          n: 1,
          response_format: "b64_json",
          size: imageSize
        };
        const editData = await tryPostJSON(editUrl, editBody, attempts);
        const first = editData?.data?.[0] || {};
        const b64 = first?.b64_json || first?.image_base64 || first?.image || "";
        if (b64) return String(b64);
        const urlOut = first?.url || first?.image_url;
        if (urlOut) {
          const r = await axiosWithRetry({ method: "GET", url: String(urlOut), responseType: "arraybuffer" });
          const buf: any = r.data;
          const b: Buffer = Buffer.isBuffer(buf) ? buf : Buffer.from(buf);
          if (b && b.length > 0) return b.toString("base64");
        }
      } catch { }
    }
    throw err;
  }
};
const imageGemini = async (p: Provider, model: string, prompt: string, sourceImage?: { data: string; mime: string }): Promise<{ image?: Buffer; text?: string; mime?: string }> => {
  let imageModel = model;
  if (!model.includes("image") && !model.includes("2.5-flash") && !model.includes("2.0-flash") && !model.includes("3-pro")) {
    imageModel = "gemini-2.5-flash-image-preview";
  }
  const path = `/models/${encodeURIComponent(imageModel)}:generateContent`;

  // æ„å»ºè¯·æ±‚å†…å®¹ - æ”¯æŒå›¾ç”Ÿå›¾
  const parts: any[] = [];
  if (sourceImage) {
    // å›¾ç”Ÿå›¾ï¼šå…ˆæ·»åŠ åŸå›¾ï¼Œå†æ·»åŠ æç¤ºè¯
    parts.push({
      inlineData: {
        mimeType: sourceImage.mime,
        data: sourceImage.data
      }
    });
  }
  parts.push({ text: prompt });

  try {
    const data = await geminiRequestWithFallback(p, path, {
      method: "POST",
      data: {
        contents: [{ role: "user", parts }],
        generationConfig: { responseModalities: ["TEXT", "IMAGE"], temperature: 0.7, maxOutputTokens: 2048 }
      },
      params: { key: p.apiKey }
    });
    const responseParts = data?.candidates?.[0]?.content?.parts || [];
    let text: string | undefined;
    let image: Buffer | undefined;
    let mime: string | undefined;
    for (const part of responseParts) {
      const pAny: any = part;
      if (pAny?.text) {
        const rawText = String(pAny.text);
        // æ¸…ç†æ€è€ƒæ ‡ç­¾
        const cleanedText = cleanAIThinking(rawText);

        // å°è¯•ä»æ–‡æœ¬ä¸­æå–å†…åµŒçš„ data URI å›¾ç‰‡
        const embeddedImages = extractEmbeddedImages(cleanedText);
        if (embeddedImages.length > 0) {
          // ä½¿ç”¨ç¬¬ä¸€å¼ æå–åˆ°çš„å›¾ç‰‡
          const firstImg = embeddedImages[0];
          image = Buffer.from(firstImg.data, "base64");
          mime = firstImg.mime;
          // æ¸…ç†å›¾ç‰‡æ•°æ®åçš„æ–‡æœ¬
          const remainingText = cleanEmbeddedImages(cleanedText).replace(/\[å›¾ç‰‡\]/g, "").replace(/\[å›¾ç‰‡æ•°æ®\]/g, "").trim();
          if (remainingText && remainingText.length > 10) {
            text = remainingText;
          }
        } else {
          text = cleanedText;
        }
      }
      const inline = pAny?.inlineData || pAny?.inline_data;
      if (inline?.data) {
        image = Buffer.from(inline.data, "base64");
        mime = inline?.mimeType || inline?.mime_type || "image/png";
      }
      const fileUri = pAny?.fileData?.fileUri || pAny?.file_data?.file_uri;
      if (fileUri) {
        const hint = `ç”Ÿæˆçš„å›¾ç‰‡å·²æä¾›æ–‡ä»¶URIï¼š${String(fileUri)}`;
        text = text ? `${text}\n${hint}` : hint;
      }
    }
    return { image, text, mime };
  } catch (err: any) {
    const body = err?.response?.data;
    const msg = body?.error?.message || body?.message || err?.message || String(err);
    throw new Error(`å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š${msg}`);
  }
};

/* ---------- TTS ---------- */
const ttsGemini = async (p: Provider, model: string, input: string, voiceName?: string): Promise<{ audio?: Buffer; mime?: string }> => {
  const path = `/models/${encodeURIComponent(model)}:generateContent`;
  const voice = voiceName || "Kore";
  const buildPayloads = () => [
    {
      contents: [{ role: "user", parts: [{ text: input }] }],
      generationConfig: {
        responseModalities: ["AUDIO"],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: voice } } }
      }
    },
    {
      contents: [{ role: "user", parts: [{ text: input }] }],
      generationConfig: { responseModalities: ["AUDIO"] }
    }
  ];
  try {
    const payloads = buildPayloads();
    for (let i = 0; i < payloads.length; i++) {
      const payload = payloads[i];
      try {
        const data = await geminiRequestWithFallback(p, path, {
          method: "POST",
          data: payload,
          params: { key: p.apiKey },
          timeout: 60000
        });
        const parts = data?.candidates?.[0]?.content?.parts || [];
        for (const part of parts) {
          const pAny: any = part;
          const inline = pAny?.inlineData || pAny?.inline_data;
          const d = inline?.data;
          const m = inline?.mimeType || inline?.mime_type || "audio/ogg";
          if (d && String(m).startsWith("audio/")) {
            const audio = Buffer.from(d, "base64");
            const mime = m;
            return { audio, mime };
          }
        }
      } catch {
        // Payload å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
      }
    }
    return {};
  } catch {
    return {};
  }
};
const ttsOpenAI = async (p: Provider, model: string, input: string, voiceName?: string): Promise<Buffer> => {
  const base = trimBase(p.baseUrl);
  const paths = ["/v1/audio/speech", "/v1/audio/tts", "/audio/speech"];
  const payload = { model, input, voice: voiceName || "alloy", format: "opus" };
  const attempts = buildAuthAttempts(p, { "Content-Type": "application/json" });
  let lastErr: any;
  for (const pth of paths) {
    const url = base + pth;
    for (const a of attempts) {
      try {
        const r = await axiosWithRetry({ method: "POST", url, data: payload, responseType: "arraybuffer", ...(a || {}), timeout: 60000 });
        const data: any = r.data;
        const buf: Buffer = Buffer.isBuffer(data) ? data : Buffer.from(data);
        if (buf && buf.length > 0) return buf;
      } catch (err: any) {
        lastErr = err;
      }
    }
  }
  const status = lastErr?.response?.status;
  const bodyErr = lastErr?.response?.data;
  const msg = bodyErr?.error?.message || bodyErr?.message || lastErr?.message || String(lastErr);
  throw new Error(`[ttsOpenAI] adapter=openai model=${html(model)} status=${status || "network"} message=${msg}`);
};

/* ---------- PCM -> WAV ---------- */
const convertPcmL16ToWavIfNeeded = (raw: Buffer, mime?: string): { buf: Buffer; mime: string } => {
  let buf = raw;
  let outMime = mime || "audio/ogg";
  const lm = outMime.toLowerCase();
  if (lm.includes("l16") && lm.includes("pcm")) {
    try {
      const parse = (mt: string) => {
        const [fileType, ...params] = mt.split(";").map(s => s.trim());
        const [, format] = (fileType || "").split("/");
        const opts: any = { numChannels: 1, sampleRate: 24000, bitsPerSample: 16 };
        if (format && format.toUpperCase().startsWith("L")) {
          const bits = parseInt(format.slice(1), 10);
          if (!isNaN(bits)) opts.bitsPerSample = bits;
        }
        for (const param of params) {
          const [k, v] = param.split("=").map(s => s.trim());
          if (k === "rate") { const r = parseInt(v, 10); if (!isNaN(r)) opts.sampleRate = r; }
          if (k === "channels") { const c = parseInt(v, 10); if (!isNaN(c)) opts.numChannels = c; }
        }
        return opts;
      };
      const createHeader = (len: number, o: any) => {
        const byteRate = o.sampleRate * o.numChannels * o.bitsPerSample / 8;
        const blockAlign = o.numChannels * o.bitsPerSample / 8;
        const b = Buffer.alloc(44);
        b.write("RIFF", 0);
        b.writeUInt32LE(36 + len, 4);
        b.write("WAVE", 8);
        b.write("fmt ", 12);
        b.writeUInt32LE(16, 16);
        b.writeUInt16LE(1, 20);
        b.writeUInt16LE(o.numChannels, 22);
        b.writeUInt32LE(o.sampleRate, 24);
        b.writeUInt32LE(byteRate, 28);
        b.writeUInt16LE(blockAlign, 32);
        b.writeUInt16LE(o.bitsPerSample, 34);
        b.write("data", 36);
        b.writeUInt32LE(len, 40);
        return b;
      };
      const opts = parse(outMime);
      const header = createHeader(buf.length, opts);
      buf = Buffer.concat([header, buf]);
      outMime = "audio/wav";
    } catch { }
  }
  return { buf, mime: outMime };
};

/* ---------- è¯­éŸ³å‘é€ ---------- */
const sendVoiceWithCaption = async (msg: Api.Message, fileBuf: Buffer, caption: string, replyToId?: number): Promise<void> => {
  try {
    const file: any = Object.assign(fileBuf, { name: "ai.ogg" });
    await msg.client?.sendFile(msg.peerId, {
      file,
      caption,
      parseMode: "html",
      replyTo: replyToId || undefined,
      attributes: [new Api.DocumentAttributeAudio({ duration: 0, voice: true })]
    });
  } catch (error: any) {
    if (error?.message?.includes("CHAT_SEND_VOICES_FORBIDDEN") || error?.message?.includes("VOICES_FORBIDDEN")) {
      try {
        const altFile: any = Object.assign(fileBuf, { name: "ai.wav" });
        await msg.client?.sendFile(msg.peerId, {
          file: altFile,
          caption,
          parseMode: "html",
          replyTo: replyToId || undefined
        });
        return;
      } catch {
        // å›é€€åˆ°æ–‡æœ¬æ¶ˆæ¯
        const fallbackText = caption + "\n\nâš ï¸ è¯­éŸ³å‘é€è¢«ç¦æ­¢ï¼Œå·²è½¬ä¸ºæ–‡æœ¬æ¶ˆæ¯";
        if (replyToId) {
          await msg.client?.sendMessage(msg.peerId, { message: fallbackText, parseMode: "html", replyTo: replyToId });
        } else {
          await msg.client?.sendMessage(msg.peerId, { message: fallbackText, parseMode: "html" });
        }
      }
    } else {
      throw error;
    }
  }
};

/* ---------- å›¾ç‰‡å‘é€ ---------- */
const sendImageFile = async (msg: Api.Message, buf: Buffer, caption: string, replyToId?: number, mimeHint?: string): Promise<void> => {
  const ext = (mimeHint || "image/png").includes("png") ? "png" : (mimeHint || "").includes("jpeg") ? "jpg" : "png";
  const file: any = Object.assign(buf, { name: `ai.${ext}` });
  await msg.client?.sendFile(msg.peerId, { file, caption, parseMode: "html", replyTo: replyToId || undefined });
};

/* ---------- é•¿æ–‡è‡ªåŠ¨é€‰æ‹© ---------- */
const sendLongAuto = async (msg: Api.Message, text: string, replyToId?: number, opts?: { collapse?: boolean }, postfix?: string): Promise<void> => {
  if (replyToId) await sendLongReply(msg, replyToId, text, opts, postfix);
  else await sendLong(msg, text, opts, postfix);
};

// å…¬å…± TTS æ‰§è¡Œå‡½æ•°
const executeTTS = async (msg: Api.Message, text: string, replyToId: number): Promise<boolean> => {
  const m = pick("tts");
  if (!m) { await msg.edit({ text: "âŒ æœªè®¾ç½® tts æ¨¡å‹", parseMode: "html" }); return false; }
  const p = providerOf(m.provider);
  if (!p?.apiKey) { await msg.edit({ text: "âŒ æœåŠ¡å•†/ä»¤ç‰Œæœªé…ç½®", parseMode: "html" }); return false; }
  const compat = await resolveCompat(m.provider, m.model, p);
  if (!Store.data.voices) Store.data.voices = { gemini: "Kore", openai: "alloy" };
  const voice = compat === "gemini" ? Store.data.voices.gemini : Store.data.voices.openai;
  await msg.edit({ text: "ğŸ”Š åˆæˆä¸­...", parseMode: "html" });
  try {
    if (compat === "openai") {
      const audio = await ttsOpenAI(p, m.model, text, voice);
      await sendVoiceWithCaption(msg, audio, "", replyToId);
    } else if (compat === "gemini") {
      const { audio, mime } = await ttsGemini(p, m.model, text, voice);
      if (!audio) { await msg.edit({ text: "âŒ è¯­éŸ³åˆæˆå¤±è´¥", parseMode: "html" }); return false; }
      const { buf } = convertPcmL16ToWavIfNeeded(audio, mime);
      await sendVoiceWithCaption(msg, buf, "", replyToId);
    } else {
      await msg.edit({ text: "âŒ å½“å‰æœåŠ¡å•†ä¸æ”¯æŒè¯­éŸ³åˆæˆ", parseMode: "html" }); return false;
    }
    await msg.delete();
    return true;
  } catch (e: any) {
    await msg.edit({ text: `âŒ è¯­éŸ³åˆæˆå¤±è´¥: ${html(e?.message || e)}`, parseMode: "html" });
    return false;
  }
};


/* ---------- æ¨¡å‹åˆ—è¡¨è§£æ ---------- */
const parseModelListFromResponse = (data: any): string[] => {
  const arr = Array.isArray(data) ? data : data?.data || data?.models || [];
  return (arr || []).map((x: any) => normalizeModelName(x));
};

/* ---------- æŒ‰å…¼å®¹ç±»å‹æšä¸¾æ¨¡å‹ ---------- */
const listModels = async (p: Provider, compat: Compat): Promise<string[]> => {
  const base = trimBase(p.baseUrl);
  const tryGet = async (url: string, headers: Record<string, string> = {}, prefer?: Compat) => {
    const attempts = buildAuthAttempts({ ...p, compatauth: prefer || p.compatauth } as Provider, headers);
    let lastErr: any;
    for (const a of attempts) {
      try {
        const r = await axiosWithRetry({ method: "GET", url, ...(a || {}) });
        return r.data;
      } catch (e: any) {
        lastErr = e;
      }
    }
    throw lastErr;
  };
  let lastErr: any = null;
  if (compat === "openai") {
    const url = base + "/v1/models";
    try {
      const data = await tryGet(url);
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const vAnth = await getAnthropicVersion(p);
      const data = await tryGet(url, { "anthropic-version": vAnth }, "claude");
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const data = await tryGet(base + "/v1beta/models", {}, "gemini");
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
  } else if (compat === "claude") {
    const url = base + "/v1/models";
    try {
      const vAnth = await getAnthropicVersion(p);
      const data = await tryGet(url, { "anthropic-version": vAnth }, "claude");
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const data = await tryGet(url);
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const data = await tryGet(base + "/v1beta/models", {}, "gemini");
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
  } else {
    const url1 = base + "/v1beta/models";
    const url2 = base + "/v1/models";
    try {
      const data = await tryGet(url1, {}, "gemini");
      const list = parseModelListFromResponse(data);
      if (list.length) return list;
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const data = await tryGet(url2, {}, "gemini");
      const list = parseModelListFromResponse(data);
      if (list.length) return list;
    } catch (e: any) {
      lastErr = e;
    }
    try {
      const data = await tryGet(url2);
      return parseModelListFromResponse(data);
    } catch (e: any) {
      lastErr = e;
    }
  }
  if (lastErr) throw lastErr;
  throw new Error("æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼šæœåŠ¡æ— æœ‰æ•ˆè¾“å‡º");
};
const listModelsByAnyCompat = async (p: Provider): Promise<{ models: string[]; compat: Compat | null; compats: Compat[]; modelMap?: Record<string, Compat> }> => {
  // å¦‚æœè®¾ç½®äº†å›ºå®šå…¼å®¹ç±»å‹ï¼Œè·³è¿‡æ¨¡å‹åˆ—è¡¨æ£€æµ‹
  if (p.fixedCompat) {
    return { 
      models: [], 
      compat: p.fixedCompat, 
      compats: [p.fixedCompat],
      modelMap: {}
    };
  }
  
  const order: Compat[] = ["openai", "gemini", "claude"];
  const merged = new Map<string, string>();
  const compats: Compat[] = [];
  const modelMap: Record<string, Compat> = {};
  let primary: Compat | null = null;
  for (const c of order) {
    try {
      const list = await listModels(p, c);
      if (Array.isArray(list) && list.length) {
        if (!primary) primary = c;
        if (!compats.includes(c)) compats.push(c);
        for (const m of list) {
          const k = String(m || "").toLowerCase();
          if (k && !merged.has(k)) merged.set(k, m);
          if (k && modelMap[k] === undefined) modelMap[k] = c;
        }
      }
    } catch { }
  }
  for (const k of Object.keys(modelMap)) {
    const g = detectCompat(k);
    if ((g === "gemini" || g === "claude") && modelMap[k] !== g) modelMap[k] = g;
  }
  return { models: Array.from(merged.values()), compat: primary, compats, modelMap };
};

/* ---------- é¢„è®¾ Prompt åº”ç”¨ ---------- */
const applyPresetPrompt = (userInput: string): string => {
  const preset = Store.data.presetPrompt || "";
  if (!preset.trim()) return userInput;
  return `${preset}\n\n${userInput}`;
};

/* ---------- ç»Ÿä¸€èŠå¤©è°ƒç”¨ ---------- */
const callChat = async (kind: "chat" | "search", text: string, msg: Api.Message): Promise<{ content: string; model: string }> => {
  const startTime = Date.now();
  const m = pick(kind);
  if (!m) throw new Error(`æœªè®¾ç½®${kind}æ¨¡å‹ï¼Œè¯·å…ˆé…ç½®`);
  const p = providerOf(m.provider);
  if (!p) throw new Error(`æœåŠ¡å•† ${m.provider} æœªé…ç½®`);
  
  // æ£€æŸ¥ç¼“å­˜
  const cached = requestCache.get(m.provider, m.model, text);
  if (cached && kind === "chat") {
    return { content: cached.content + "\n\n<i>(æ¥è‡ªç¼“å­˜)</i>", model: cached.model };
  }
  
  const compat = await resolveCompat(m.provider, m.model, p);
  const id = chatIdStr(msg);
  const msgs: { role: string; content: string }[] = [];
  const processedText = applyPresetPrompt(text);
  msgs.push({ role: "user", content: processedText });
  let out = "";
  let isError = false;
  try {
    const isSearch = kind === "search";
    if (compat === "openai") out = await chatOpenAI(p, m.model, msgs, undefined, isSearch);
    else if (compat === "claude") out = await chatClaude(p, m.model, msgs, undefined, isSearch);
    else out = await chatGemini(p, m.model, msgs, isSearch);
  } catch (e: any) {
    isError = true;
    const em = e?.message || String(e);
    throw new Error(`[${kind}] provider=${m.provider} compat=${compat} model=${html(m.model)} :: ${em}`);
  } finally {
    // è®°å½•ç»Ÿè®¡
    const latency = Date.now() - startTime;
    recordRequest(m.provider, latency, isError);
  }
  
  // ä¿å­˜åˆ°ç¼“å­˜
  if (!isError && kind === "chat") {
    requestCache.set(m.provider, m.model, text, out);
  }
  
  if (Store.data.contextEnabled) {
    pushHist(id, "user", text);
    pushHist(id, "assistant", out);
    await Store.writeSoon();
  }
  return { content: out, model: m.model };
};



/* ---------- å¸®åŠ©æ–‡æ¡ˆ ---------- */
const help_text = `ğŸ”§ âœ¨ <b>æ–°å¢åŠŸèƒ½</b>
â€¢ ğŸ’¾ æ™ºèƒ½ç¼“å­˜ï¼šç›¸åŒé—®é¢˜3åˆ†é’Ÿå†…å¿«é€Ÿå›å¤
â€¢ ğŸ“Š ä½¿ç”¨ç»Ÿè®¡ï¼š.ai stats æŸ¥çœ‹ API è°ƒç”¨æƒ…å†µ
â€¢ ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ›´æ™ºèƒ½çš„å›¾ç‰‡å‹ç¼©

ğŸ“ <b>ç‰¹æ€§</b>
å…¼å®¹ Google Geminiã€OpenAIã€Anthropic Claudeã€Baidu æ ‡å‡†æ¥å£ï¼Œç»Ÿä¸€æŒ‡ä»¤ï¼Œä¸€å¤„é…ç½®ï¼Œå¤šå¤„å¯ç”¨ã€‚

âœ¨ <b>äº®ç‚¹</b>
â€¢ ğŸ”€ æ¨¡å‹æ··ç”¨ï¼šå¯¹è¯ / æœç´¢ / å›¾ç‰‡ / è¯­éŸ³ å¯åˆ†åˆ«æŒ‡å®šä¸åŒæœåŠ¡å•†çš„ä¸åŒæ¨¡å‹
â€¢ ğŸ§  å¯é€‰ä¸Šä¸‹æ–‡è®°å¿†ã€ğŸ“° é•¿æ–‡è‡ªåŠ¨å‘å¸ƒ Telegraphã€ğŸ§¾ æ¶ˆæ¯æŠ˜å æ˜¾ç¤º
â€¢ ğŸ¯ å…¨å±€Prompté¢„è®¾ï¼šä¸ºæ‰€æœ‰å¯¹è¯è®¾ç½®ç»Ÿä¸€çš„ç³»ç»Ÿæç¤ºè¯

<blockquote expandable>ğŸ’¬ <b>å¯¹è¯</b>
<code>${mainPrefix}ai chat [é—®é¢˜]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai chat ä½ å¥½ï¼Œå¸®æˆ‘ç®€å•ä»‹ç»ä¸€ä¸‹ä½ </code>
â€¢ æ”¯æŒå¤šè½®å¯¹è¯ï¼ˆå¯æ‰§è¡Œ <code>${mainPrefix}ai context on</code> å¼€å¯è®°å¿†ï¼‰
â€¢ è¶…é•¿å›ç­”å¯è‡ªåŠ¨è½¬ Telegraph

ğŸ” <b>æœç´¢</b>
<code>${mainPrefix}ai search [æŸ¥è¯¢]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai search 2024 å¹´ AI æŠ€æœ¯è¿›å±•</code>

ğŸ–¼ï¸ <b>å›¾ç‰‡</b>
<code>${mainPrefix}ai image [æè¿°]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai image æœªæ¥åŸå¸‚çš„ç§‘å¹»å¤œæ™¯</code>

ğŸµ <b>æ–‡æœ¬è½¬è¯­éŸ³</b>
<code>${mainPrefix}ai tts [æ–‡æœ¬]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai tts ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ¬¡è¯­éŸ³åˆæˆæµ‹è¯•</code>

ğŸ¤ <b>è¯­éŸ³å›ç­”</b>
<code>${mainPrefix}ai audio [é—®é¢˜]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai audio ç”¨ 30 ç§’ä»‹ç»äººå·¥æ™ºèƒ½çš„å‘å±•</code>

ğŸ”ğŸ¤ <b>æœç´¢å¹¶è¯­éŸ³å›ç­”</b>
<code>${mainPrefix}ai searchaudio [æŸ¥è¯¢]</code>
â€¢ ç¤ºä¾‹ï¼š<code>${mainPrefix}ai searchaudio 2024 å¹´æœ€æ–°ç§‘æŠ€è¶‹åŠ¿</code>

ğŸ¯ <b>å…¨å±€Prompté¢„è®¾</b>
<code>${mainPrefix}ai prompt set [å†…å®¹]</code> - è®¾ç½®å…¨å±€Prompté¢„è®¾
<code>${mainPrefix}ai prompt clear</code> - æ¸…é™¤å…¨å±€Prompté¢„è®¾
<code>${mainPrefix}ai prompt show</code> - æ˜¾ç¤ºå½“å‰Prompté¢„è®¾
â€¢ é¢„è®¾å°†è‡ªåŠ¨æ·»åŠ åˆ°æ‰€æœ‰å¯¹è¯è¯·æ±‚å‰ï¼Œé€‚ç”¨äºè§’è‰²è®¾å®šã€å›ç­”é£æ ¼ç­‰ç»Ÿä¸€é…ç½®

ğŸ’­ <b>å¯¹è¯ä¸Šä¸‹æ–‡</b>
<code>${mainPrefix}ai context on|off|show|del</code>

ğŸ“‹ <b>æ¶ˆæ¯æŠ˜å </b>
<code>${mainPrefix}ai collapse on|off</code>

ğŸ“° <b>Telegraph é•¿æ–‡</b>
<code>${mainPrefix}ai telegraph on|off|limit &lt;æ•°é‡&gt;|list|del &lt;n|all&gt;</code>
â€¢ limit &lt;æ•°é‡&gt;ï¼šè®¾ç½®å­—æ•°é˜ˆå€¼ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
â€¢ è‡ªåŠ¨åˆ›å»º / ç®¡ç† / åˆ é™¤ Telegraph æ–‡ç« 

ğŸ¤ <b>éŸ³è‰²ç®¡ç†</b>
<code>${mainPrefix}ai voice list</code> - æŸ¥çœ‹æ‰€æœ‰å¯ç”¨éŸ³è‰²ï¼ˆGemini 30ç§ / OpenAI 6ç§ï¼‰
<code>${mainPrefix}ai voice show</code> - æŸ¥çœ‹å½“å‰éŸ³è‰²é…ç½®
<code>${mainPrefix}ai voice gemini [éŸ³è‰²å]</code> - è®¾ç½® Gemini TTS éŸ³è‰²
<code>${mainPrefix}ai voice openai [éŸ³è‰²å]</code> - è®¾ç½® OpenAI TTS éŸ³è‰²
â€¢ Gemini éŸ³è‰²ç¤ºä¾‹ï¼šKore, Puck, Charon, Leda, Aoede ç­‰
â€¢ OpenAI éŸ³è‰²ç¤ºä¾‹ï¼šalloy, echo, fable, onyx, nova, shimmer

âš™ï¸ <b>æ¨¡å‹ç®¡ç†</b>
<code>${mainPrefix}ai model list</code> - æŸ¥çœ‹å½“å‰æ¨¡å‹é…ç½®
<code>${mainPrefix}ai model chat|search|image|tts [æœåŠ¡å•†] [æ¨¡å‹]</code> - è®¾ç½®å„åŠŸèƒ½æ¨¡å‹
<code>${mainPrefix}ai model default</code> - æ¸…ç©ºæ‰€æœ‰åŠŸèƒ½æ¨¡å‹
<code>${mainPrefix}ai model auto</code> - æ™ºèƒ½åˆ†é… chat/search/image/tts

ğŸ”§ <b>é…ç½®ç®¡ç†</b>
<code>${mainPrefix}ai config status</code> - æ˜¾ç¤ºé…ç½®æ¦‚è§ˆ
<code>${mainPrefix}ai config add [æœåŠ¡å•†] [APIå¯†é’¥] [BaseURL]</code>
<code>${mainPrefix}ai config list</code> - æŸ¥çœ‹å·²é…ç½®çš„æœåŠ¡å•†
<code>${mainPrefix}ai config model [æœåŠ¡å•†]</code> - æŸ¥çœ‹è¯¥æœåŠ¡å•†å¯ç”¨æ¨¡å‹
<code>${mainPrefix}ai config update [æœåŠ¡å•†] [apikey|baseurl] [å€¼]</code>
<code>${mainPrefix}ai config remove [æœåŠ¡å•†|all]</code>

ğŸ“ <b>é…ç½®ç¤ºä¾‹</b>
â€¢ OpenAIï¼š<code>${mainPrefix}ai config add openai sk-proj-xxx https://api.openai.com</code>
â€¢ DeepSeekï¼š<code>${mainPrefix}ai config add deepseek sk-xxx https://api.deepseek.com</code>
â€¢ Grokï¼š<code>${mainPrefix}ai config add grok xai-xxx https://api.x.ai</code>
â€¢ Claudeï¼š<code>${mainPrefix}ai config add claude sk-ant-xxx https://api.anthropic.com</code>
â€¢ Geminiï¼š<code>${mainPrefix}ai config add gemini AIzaSy-xxx https://generativelanguage.googleapis.com</code>

âš¡ <b>ç®€æ´å‘½ä»¤ä¸åˆ«å</b>
å¸¸ç”¨ç®€å†™
â€¢ å¯¹è¯ï¼š<code>${mainPrefix}ai [é—®é¢˜]</code>æˆ–<code>${mainPrefix}ai chat [é—®é¢˜]</code>
â€¢ æœç´¢ï¼š<code>${mainPrefix}ai s [æŸ¥è¯¢]</code>
â€¢ å›¾ç‰‡ï¼š<code>${mainPrefix}ai img [æè¿°]</code>
â€¢ è¯­éŸ³ï¼š<code>${mainPrefix}ai v [æ–‡æœ¬]</code>
â€¢ å›ç­”ä¸ºè¯­éŸ³ï¼š<code>${mainPrefix}ai a [é—®é¢˜]</code> / æœç´¢å¹¶è¯­éŸ³ï¼š<code>${mainPrefix}ai sa [æŸ¥è¯¢]</code>
â€¢ ä¸Šä¸‹æ–‡ï¼š<code>${mainPrefix}ai ctx on|off</code>
â€¢ æ¨¡å‹ï¼š<code>${mainPrefix}ai m list</code> / è®¾ç½®ï¼š<code>${mainPrefix}ai m chat|search|image|tts [æœåŠ¡å•†] [æ¨¡å‹]</code>
â€¢ é…ç½®ï¼š<code>${mainPrefix}ai c add [æœåŠ¡å•†] [APIå¯†é’¥] [BaseURL]</code>
â€¢ åˆ«åï¼š<code>s</code>=search, <code>img</code>/<code>i</code>=image, <code>v</code>=tts, <code>a</code>=audio, <code>sa</code>=searchaudio, <code>ctx</code>=context, <code>fold</code>=collapse, <code>cfg</code>/<code>c</code>=config, <code>m</code>=model

â±ï¸ <b>è¶…æ—¶è®¾ç½®</b>
<code>${mainPrefix}ai timeout</code> - æŸ¥çœ‹å½“å‰è¶…æ—¶æ—¶é—´
<code>${mainPrefix}ai timeout set [ç§’]</code> - è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆ10-600ç§’ï¼‰
<code>${mainPrefix}ai timeout reset</code> - é‡ç½®ä¸ºé»˜è®¤å€¼ï¼ˆ30ç§’ï¼‰

ğŸ“ <b>æœ€å¤§è¾“å‡º Token</b>
<code>${mainPrefix}ai maxtokens</code> - æŸ¥çœ‹å½“å‰è®¾ç½®
<code>${mainPrefix}ai maxtokens set [æ•°é‡]</code> - è®¾ç½®æœ€å¤§è¾“å‡º tokenï¼ˆ100-128000ï¼‰
<code>${mainPrefix}ai maxtokens reset</code> - é‡ç½®ä¸ºé»˜è®¤å€¼ï¼ˆ16384ï¼Œçº¦8000ä¸­æ–‡å­—ï¼‰
â€¢ ç”Ÿæˆè¶…é•¿æ–‡æœ¬æ—¶éœ€å¢å¤§æ­¤å€¼ï¼ŒåŒæ—¶å»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´

ğŸ”— <b>é“¾æ¥é¢„è§ˆ</b>
<code>${mainPrefix}ai preview</code> - æŸ¥çœ‹å½“å‰çŠ¶æ€
<code>${mainPrefix}ai preview on|off</code> - å¼€å¯/å…³é—­é“¾æ¥é¢„è§ˆ
</blockquote>`;


/* ---------- æ’ä»¶ä¸»ä½“ ---------- */
class AiPlugin extends Plugin {
  name = "NexAI";
  description = "ğŸ¤– æ™ºèƒ½AIåŠ©æ‰‹ - å…¼å®¹ OpenAI/Gemini/Claude/ç«å±±ç­‰æ¥å£ï¼Œæ”¯æŒå¯¹è¯/æœç´¢/ç”Ÿå›¾/TTS/è¯­éŸ³å›ç­”";
  cmdHandlers = {
    ai: async (msg: Api.Message) => {
      await Store.init();
      ensureDir();
      const text = (msg as any).text || (msg as any).message || "";
      const lines = text.trim().split(/\r?\n/g);
      const parts = (lines[0] || "").split(/\s+/);
      const [, sub, ...args] = parts;
      const subl = (sub || "").toLowerCase();
      const aliasMap: Record<string, string> = {
        s: "search",
        img: "image",
        i: "image",
        v: "tts",
        a: "audio",
        sa: "searchaudio",
        ctx: "context",
        fold: "collapse",
        cfg: "config",
        c: "config",
        m: "model"
      };
      const subn = aliasMap[subl] || subl;
      const knownSubs = [
        "config", "model", "context", "collapse", "telegraph", "voice", "prompt",
        "chat", "search", "image", "tts", "audio", "searchaudio", "help", "timeout", "preview", "maxtokens"
      ];
      const isUnknownBareQuery = !!subn && !knownSubs.includes(subn);
      try {
        const preflight = async (kind: keyof Models): Promise<{ m: { provider: string; model: string }; p: Provider; compat: Compat } | null> => {
          const m = pick(kind);
          if (!m) { await msg.edit({ text: `âŒ æœªè®¾ç½® ${kind} æ¨¡å‹`, parseMode: "html" }); return null; }
          const p = providerOf(m.provider);
          if (!p) { await msg.edit({ text: "âŒ æœåŠ¡å•†æœªé…ç½®", parseMode: "html" }); return null; }
          if (!p.apiKey) { await msg.edit({ text: "âŒ æœªæä¾›ä»¤ç‰Œï¼Œè¯·å…ˆé…ç½® API Keyï¼ˆai config add/updateï¼‰", parseMode: "html" }); return null; }
          const compat = await resolveCompat(m.provider, m.model, p);
          return { m, p, compat };
        };

        /* ---------- å¸®åŠ©å‘½ä»¤ ---------- */
        if (subn === "help" || subn === "h" || subn === "?") {
          await sendLong(msg, help_text);
          return;
        }

        /* ---------- Prompt é¢„è®¾ç®¡ç† ---------- */
        if (subn === "prompt") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "set") {
            // æ”¯æŒå¤šè¡Œ Promptï¼šä»åŸå§‹æ–‡æœ¬ä¸­æå– "prompt set" åçš„å…¨éƒ¨å†…å®¹
            const fullText = (msg as any).text || (msg as any).message || "";
            // åŒ¹é… "-ai prompt set " æˆ– ".ai prompt set " ç­‰å‰ç¼€ï¼Œå¿½ç•¥å¤§å°å†™
            const promptSetMatch = fullText.match(/^[.\-\/!]ai\s+prompt\s+set\s+/i);
            let promptContent = "";
            if (promptSetMatch) {
              promptContent = fullText.slice(promptSetMatch[0].length).trim();
            } else {
              // å›é€€åˆ°æ—§é€»è¾‘ï¼ˆç†è®ºä¸Šä¸ä¼šèµ°åˆ°è¿™é‡Œï¼‰
              promptContent = args.slice(1).join(" ").trim();
            }
            if (!promptContent) {
              await msg.edit({ text: "âŒ è¯·æä¾›é¢„è®¾Promptå†…å®¹", parseMode: "html" });
              return;
            }
            Store.data.presetPrompt = promptContent;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²è®¾ç½®å…¨å±€Prompté¢„è®¾\n\n<blockquote expandable>${html(promptContent)}</blockquote>`, parseMode: "html" });
            return;
          }
          if (a0 === "clear") {
            Store.data.presetPrompt = "";
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²æ¸…é™¤å…¨å±€Prompté¢„è®¾", parseMode: "html" });
            return;
          }
          if (a0 === "show") {
            const currentPrompt = Store.data.presetPrompt || "";
            if (!currentPrompt) {
              await msg.edit({ text: "ğŸ“ å½“å‰æœªè®¾ç½®å…¨å±€Prompté¢„è®¾", parseMode: "html" });
              return;
            }
            await sendLong(msg, `ğŸ“ <b>å½“å‰å…¨å±€Prompté¢„è®¾</b>\n\n<blockquote expandable>${html(currentPrompt)}</blockquote>`);
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ prompt å­å‘½ä»¤\næ”¯æŒ: set|clear|show", parseMode: "html" });
          return;
        }

        /* ---------- ç»Ÿè®¡ ---------- */
        if (subn === "stats" || subn === "stat") {
          const sub = args[1]?.toLowerCase();
          if (sub === "reset" || sub === "clear") {
            resetStats();
            await msg.edit({ text: "âœ… ç»Ÿè®¡å·²é‡ç½®", parseMode: "html" });
          } else {
            await msg.edit({ text: getStatsText(), parseMode: "html" });
          }
          return;
        }

        /* ---------- é…ç½®ç®¡ç† ---------- */
        if (subn === "config") {
          if (isGroupOrChannel(msg)) {
            await msg.edit({ text: "âŒ ä¸ºä¿æŠ¤ç”¨æˆ·éšç§ï¼Œç¦æ­¢åœ¨å…¬å…±å¯¹è¯ç¯å¢ƒä½¿ç”¨ai configæ‰€æœ‰å­å‘½ä»¤", parseMode: "html" });
            return;
          }
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "status") {
            const cur = Store.data.models;
            const flags = [
              `â€¢ ä¸Šä¸‹æ–‡: ${Store.data.contextEnabled ? "å¼€å¯" : "å…³é—­"}`,
              `â€¢ æŠ˜å : ${Store.data.collapse ? "å¼€å¯" : "å…³é—­"}`,
              `â€¢ Telegraph: ${Store.data.telegraph.enabled ? "å¼€å¯" : "å…³é—­"}${Store.data.telegraph.enabled && Store.data.telegraph.limit ? `ï¼ˆé˜ˆå€¼ ${Store.data.telegraph.limit}ï¼‰` : ""}`,
              `â€¢ Prompté¢„è®¾: ${Store.data.presetPrompt ? "âœ… å·²è®¾ç½®" : "âŒ æœªè®¾ç½®"}`,

            ].join("\n");
            const provList = Object.entries(Store.data.providers)
              .map(([n, v]) => {
                const display = shortenUrlForDisplay(v.baseUrl);
                return `â€¢ <b>${html(n)}</b> - key:${v.apiKey ? "âœ…" : "âŒ"} base:<a href="${html(v.baseUrl)}">${html(display)}</a>`;
              })
              .join("\n") || "(ç©º)";
            const txt = `âš™ï¸ <b>AI é…ç½®æ¦‚è§ˆ</b>\n\n<b>åŠŸèƒ½æ¨¡å‹</b>\n<b>chat:</b> <code>${html(cur.chat) || "(æœªè®¾)"}</code>\n<b>search:</b> <code>${html(cur.search) || "(æœªè®¾)"}</code>\n<b>image:</b> <code>${html(cur.image) || "(æœªè®¾)"}</code>\n<b>tts:</b> <code>${html(cur.tts) || "(æœªè®¾)"}</code>\n\n<b>åŠŸèƒ½å¼€å…³</b>\n${flags}\n\n<b>æœåŠ¡å•†</b>\n${provList}`;
            await sendLong(msg, txt);
            return;
          }
          if (a0 === "add") {
            const [name, key, baseUrl] = [args[1], args[2], args[3]];
            if (!name || !key || !baseUrl) {
              await msg.edit({ text: "âŒ å‚æ•°ä¸è¶³", parseMode: "html" });
              return;
            }
            try {
              const u = new URL(baseUrl);
              if (u.protocol !== "http:" && u.protocol !== "https:") {
                await msg.edit({ text: "âŒ baseUrl æ— æ•ˆï¼Œè¯·ä½¿ç”¨ http/https åè®®", parseMode: "html" });
                return;
              }
            } catch {
              await msg.edit({ text: "âŒ baseUrl æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºåˆæ³• URL", parseMode: "html" });
              return;
            }
            Store.data.providers[name] = { apiKey: key, baseUrl: trimBase(baseUrl.trim()) };
            if (Store.data.modelCompat) delete Store.data.modelCompat[name];
            compatResolving.delete(name);
            await Store.writeSoon();
            debouncedRefreshModelCatalog();
            await msg.edit({ text: `âœ… å·²æ·»åŠ  <b>${html(name)}</b>`, parseMode: "html" });
            return;
          }
          if (a0 === "update") {
            const [name, field, ...rest] = args.slice(1);
            const value = (rest.join(" ") || "").trim();
            if (!name || !field || !value) {
              await msg.edit({ text: "âŒ å‚æ•°ä¸è¶³", parseMode: "html" });
              return;
            }
            const p = Store.data.providers[name];
            if (!p) {
              await msg.edit({ text: "âŒ æœªæ‰¾åˆ°æœåŠ¡å•†", parseMode: "html" });
              return;
            }
            if (field.toLowerCase() === "apikey") {
              p.apiKey = value;
              delete (p as any).compatauth;
            } else if (field.toLowerCase() === "baseurl") {
              try {
                const u = new URL(value);
                if (u.protocol !== "http:" && u.protocol !== "https:") {
                  await msg.edit({ text: "âŒ baseUrl æ— æ•ˆï¼Œè¯·ä½¿ç”¨ http/https åè®®", parseMode: "html" });
                  return;
                }
              } catch {
                await msg.edit({ text: "âŒ baseUrl æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºåˆæ³• URL", parseMode: "html" });
                return;
              }
              p.baseUrl = trimBase(value.trim());
              delete (p as any).compatauth;
            } else {
              await msg.edit({ text: "âŒ å­—æ®µä»…æ”¯æŒ apikey|baseurl", parseMode: "html" });
              return;
            }
            if (Store.data.modelCompat) delete Store.data.modelCompat[name];
            compatResolving.delete(name);
            await Store.writeSoon();
            debouncedRefreshModelCatalog();
            await msg.edit({ text: `âœ… å·²æ›´æ–° <b>${html(name)}</b> çš„ <code>${html(field)}</code>`, parseMode: "html" });
            return;
          }
          if (a0 === "remove") {
            const target = (args[1] || "").toLowerCase();
            if (!target) {
              await msg.edit({ text: "âŒ è¯·è¾“å…¥æœåŠ¡å•†åç§°æˆ– all", parseMode: "html" });
              return;
            }
            if (target === "all") {
              Store.data.providers = {};
              Store.data.modelCompat = {};
              Store.data.modelCatalog = { map: {}, updatedAt: undefined } as any;
              compatResolving.clear();
            } else {
              if (!Store.data.providers[target]) {
                await msg.edit({ text: "âŒ æœªæ‰¾åˆ°æœåŠ¡å•†", parseMode: "html" });
                return;
              }
              delete Store.data.providers[target];
              if (Store.data.modelCompat) delete Store.data.modelCompat[target];
              const kinds: (keyof Models)[] = ["chat", "search", "image", "tts"];
              for (const k of kinds) {
                const v = Store.data.models[k];
                if (v && v.startsWith(target + " ")) Store.data.models[k] = "";
              }
            }
            await Store.writeSoon();
            debouncedRefreshModelCatalog();
            await msg.edit({ text: "âœ… å·²åˆ é™¤", parseMode: "html" });
            return;
          }
          if (a0 === "list") {
            const list = Object.entries(Store.data.providers)
              .map(([n, v]) => {
                const display = shortenUrlForDisplay(v.baseUrl);
                return `â€¢ <b>${html(n)}</b> - key:${v.apiKey ? "âœ…" : "âŒ"} base:<a href="${html(v.baseUrl)}">${html(display)}</a>`;
              })
              .join("\n") || "(ç©º)";
            await sendLong(msg, `ğŸ“¦ <b>å·²é…ç½®æœåŠ¡å•†</b>\n\n${list}`);
            return;
          }
          if (a0 === "model") {
            const name = args[1];
            const p = name && providerOf(name);
            if (!p) {
              await msg.edit({ text: "âŒ æœªæ‰¾åˆ°æœåŠ¡å•†", parseMode: "html" });
              return;
            }
            let models: string[] = [];
            let selected: Compat | null = null;
            try {
              const res = await listModelsByAnyCompat(p);
              models = res.models;
              selected = res.compat;
            } catch { }
            if (!models.length || !selected) {
              await msg.edit({ text: "âŒ è¯¥æœåŠ¡å•†çš„æƒé‰´æ–¹å¼æœªä½¿ç”¨OpenAIã€Google Geminiã€Claudeçš„æ ‡å‡†æ¥å£ï¼Œä¸åšå…¼å®¹ã€‚", parseMode: "html" });
              return;
            }
            const buckets = { chat: [] as string[], search: [] as string[], image: [] as string[], tts: [] as string[] };
            for (const m of models) {
              const ml = String(m).toLowerCase();
              if (/image|dall|sd|gpt-image/.test(ml)) buckets.image.push(m);
              else if (/tts|voice|audio\.speech|gpt-4o.*-tts|\b-tts\b/.test(ml)) buckets.tts.push(m);
              else {
                buckets.chat.push(m);
                buckets.search.push(m);
              }
            }
            const txt = `ğŸ§¾ <b>${html(name!)}</b> å¯ç”¨æ¨¡å‹\n\n<b>chat/search</b>:\n${buckets.chat.length ? buckets.chat.map(x => "â€¢ " + html(x)).join("\n") : "(ç©º)"}\n\n<b>image</b>:\n${buckets.image.length ? buckets.image.map(x => "â€¢ " + html(x)).join("\n") : "(ç©º)"}\n\n<b>tts</b>:\n${buckets.tts.length ? buckets.tts.map(x => "â€¢ " + html(x)).join("\n") : "(ç©º)"}`;
            await sendLong(msg, txt);
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ config å­å‘½ä»¤", parseMode: "html" });
          return;
        }

        /* ---------- æ¨¡å‹ç®¡ç† ---------- */
        if (subn === "model") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "list") {
            const cur = Store.data.models;
            const txt = `âš™ï¸ <b>å½“å‰æ¨¡å‹é…ç½®</b>\n\n<b>chat:</b> <code>${html(cur.chat) || "(æœªè®¾)"}</code>\n<b>search:</b> <code>${html(cur.search) || "(æœªè®¾)"}</code>\n<b>image:</b> <code>${html(cur.image) || "(æœªè®¾)"}</code>\n<b>tts:</b> <code>${html(cur.tts) || "(æœªè®¾)"}</code>`;
            await sendLong(msg, txt);
            return;
          }
          if (a0 === "default") {
            Store.data.models = { chat: "", search: "", image: "", tts: "" };
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²æ¸…ç©ºæ‰€æœ‰åŠŸèƒ½æ¨¡å‹è®¾ç½®", parseMode: "html" });
            return;
          }
          if (a0 === "auto") {
            const entries = Object.entries(Store.data.providers);
            if (!entries.length) {
              await msg.edit({ text: "âŒ è¯·å…ˆä½¿ç”¨ ai config add æ·»åŠ æœåŠ¡å•†", parseMode: "html" });
              return;
            }
            const modelsBy: Record<string, string[]> = {};
            for (const [n, p] of entries) {
              try {
                const { models } = await listModelsByAnyCompat(p);
                if (Array.isArray(models) && models.length) {
                  modelsBy[n] = models;
                } else {
                  modelsBy[n] = [];
                }
              } catch {
                modelsBy[n] = [];
              }
            }
            const bucketsBy: Record<string, { chat: string[]; search: string[]; image: string[]; tts: string[] }> = {};
            for (const [n, list] of Object.entries(modelsBy)) {
              const buckets = { chat: [] as string[], search: [] as string[], image: [] as string[], tts: [] as string[] };
              for (const m of list) {
                const ml = String(m).toLowerCase();
                if (/image|dall|sd|gpt-image/.test(ml)) buckets.image.push(m);
                else if (/tts|voice|audio\.speech|gpt-4o.*-tts|\b-tts\b/.test(ml)) buckets.tts.push(m);
                else {
                  buckets.chat.push(m);
                  buckets.search.push(m);
                }
              }
              bucketsBy[n] = buckets;
            }
            const orders: Array<Compat | "other"> = ["openai", "gemini", "claude", "other"];
            const modelFamilyOf = (m: string): Compat | "other" => {
              const s = m.toLowerCase();
              if (/(gpt-|dall-e|gpt-image|tts-1|gpt-4o|\bo[134](?:-|\b))/.test(s)) return "openai";
              if (/gemini/.test(s)) return "gemini";
              if (/claude/.test(s)) return "claude";
              return "other";
            };
            const isStable = (m: string) => !/(preview|experimental|beta|dev|test|sandbox|staging)/i.test(m);
            const labelWeight = (s: string) => {
              const l = s.toLowerCase();
              let w = 0;
              if (/ultra/.test(l)) w += 0.09; if (/\bpro\b/.test(l)) w += 0.08; if (/opus/.test(l)) w += 0.08;
              if (/sonnet/.test(l)) w += 0.07; if (/flash/.test(l)) w += 0.06; if (/haiku/.test(l)) w += 0.03;
              if (/nano|lite|mini/.test(l)) w += 0.02;
              return w;
            };
            const popularPatterns: Record<Compat | "other", RegExp> = {
              openai: /gpt-4o|gpt-4\.?1|gpt-4-turbo|gpt-4|gpt-3\.5|gpt-image|tts-1|o[134]-?mini?/i,
              claude: /claude-3\.?[57]-sonnet|claude-3-opus|claude-3-sonnet|claude-3-haiku|claude-2/i,
              gemini: /gemini-2\.5|gemini-2\.0|gemini-1\.5|gemini-1\.0/i,
              other: /deepseek|grok|llama-3|mistral|mixtral|qwen2|command-r/i
            };
            const isPopularByFamily = (m: string, family: Compat | "other") => popularPatterns[family]?.test(m) ?? false;
            const popularityWeight = (m: string, family: Compat | "other") => isPopularByFamily(m, family) ? 0.5 : 0;
            const versionScore = (m: string, family: Compat | "other") => {
              const s = String(m).toLowerCase();
              const numMatch = s.match(/(\d+(?:\.\d+)?)/);
              let base = numMatch ? parseFloat(numMatch[1]) : 0;
              if (/gpt-4o/.test(s)) base = Math.max(base, 4.01);
              if (/tts-1/.test(s)) base = Math.max(base, 1.0);
              return base + labelWeight(s) + popularityWeight(m, family);
            };
            const sortCandidates = (_kind: "chat" | "search" | "image" | "tts", family: Compat | "other", list: string[]) => {
              const preferred = list.filter(m => isPopularByFamily(m, family));
              const useList = preferred.length ? preferred : list;
              const stable = useList.filter(m => isStable(m));
              const unstable = useList.filter(m => !isStable(m));
              const cmp = (a: string, b: string) => versionScore(b, family) - versionScore(a, family);
              stable.sort(cmp);
              unstable.sort(cmp);
              return [...stable, ...unstable];
            };
            const pickAcrossKind = (kind: "chat" | "search" | "image" | "tts", preferredProvider?: string) => {
              const providerOrder = (() => {
                const names = entries.map(([n]) => n);
                if (preferredProvider && names.includes(preferredProvider)) {
                  const rest = names.filter(n => n !== preferredProvider);
                  return [preferredProvider, ...rest];
                }
                return names;
              })();
              for (const fam of orders) {
                for (const n of providerOrder) {
                  const bucket = bucketsBy[n]?.[kind] || [];
                  if (!bucket.length) continue;
                  const candidates = bucket.filter(m => modelFamilyOf(m) === fam);
                  if (!candidates.length) continue;
                  const sorted = sortCandidates(kind, fam, candidates);
                  const m = sorted[0];
                  if (m) return { n, m, c: fam };
                }
              }
              for (const n of providerOrder) {
                const bucket = bucketsBy[n]?.[kind] || [];
                if (!bucket.length) continue;
                const sorted = sortCandidates(kind, "other", bucket);
                const m = sorted[0];
                if (m) return { n, m, c: "other" as const };
              }
              return null as any;
            };
            const chatPref = pick("chat")?.provider || undefined;
            const searchPref = pick("search")?.provider || undefined;
            const imagePref = pick("image")?.provider || undefined;
            const ttsPref = pick("tts")?.provider || undefined;
            const anchorProvider = chatPref || searchPref || imagePref || ttsPref || undefined;
            const chatSel = pickAcrossKind("chat", anchorProvider);
            const searchSel = pickAcrossKind("search", anchorProvider);
            const imageSel = pickAcrossKind("image", anchorProvider);
            const ttsSel = pickAcrossKind("tts", anchorProvider);
            if (!chatSel) {
              await msg.edit({ text: "âŒ æœªåœ¨ä»»ä½•å·²é…ç½®æœåŠ¡å•†ä¸­æ‰¾åˆ°å¯ç”¨ chat æ¨¡å‹", parseMode: "html" });
              return;
            }
            const prev = { ...Store.data.models };
            Store.data.models.chat = `${chatSel.n} ${chatSel.m}`;
            Store.data.models.search = searchSel ? `${searchSel.n} ${searchSel.m}` : prev.search;
            Store.data.models.image = imageSel ? `${imageSel.n} ${imageSel.m}` : prev.image;
            Store.data.models.tts = ttsSel ? `${ttsSel.n} ${ttsSel.m}` : prev.tts;
            await Store.writeSoon();
            const cur = Store.data.models;
            const detail = `âœ… å·²æ™ºèƒ½åˆ†é… chat/search/image/tts\n\n<b>chat:</b> <code>${html(cur.chat) || "(æœªè®¾)"}</code>\n<b>search:</b> <code>${html(cur.search) || "(æœªè®¾)"}</code>\n<b>image:</b> <code>${html(cur.image) || "(æœªè®¾)"}</code>\n<b>tts:</b> <code>${html(cur.tts) || "(æœªè®¾)"}</code>`;
            await msg.edit({ text: detail, parseMode: "html" });
            return;
          }
          const kind = a0 as keyof Models;
          if (["chat", "search", "image", "tts"].includes(kind)) {
            const [provider, ...mm] = args.slice(1);
            const model = (mm.join(" ") || "").trim();
            if (!provider || !model) {
              await msg.edit({ text: "âŒ å‚æ•°ä¸è¶³", parseMode: "html" });
              return;
            }
            if (!Store.data.providers[provider]) {
              await msg.edit({ text: "âŒ æœªçŸ¥æœåŠ¡å•†", parseMode: "html" });
              return;
            }
            Store.data.models[kind] = `${provider} ${model}`;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²è®¾ç½® ${kind}: <code>${html(Store.data.models[kind])}</code>`, parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ model å­å‘½ä»¤", parseMode: "html" });
          return;
        }

        /* ---------- ä¸Šä¸‹æ–‡ç®¡ç† ---------- */
        if (subn === "context") {
          const a0 = (args[0] || "").toLowerCase();
          const id = chatIdStr(msg);
          if (a0 === "on") {
            Store.data.contextEnabled = true;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å¼€å¯ä¸Šä¸‹æ–‡", parseMode: "html" });
            return;
          }
          if (a0 === "off") {
            Store.data.contextEnabled = false;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å…³é—­ä¸Šä¸‹æ–‡", parseMode: "html" });
            return;
          }
          if (a0 === "show") {
            const items = histFor(id);
            const t = items.map(x => `${x.role}: ${html(x.content)}`).join("\n");
            await sendLong(msg, t || "(ç©º)");
            return;
          }
          if (a0 === "del") {
            const histItems = Store.data.histories[id] || [];
            const count = histItems.length;
            delete Store.data.histories[id];
            if (Store.data.histMeta) delete Store.data.histMeta[id];
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²æ¸…ç©ºæœ¬ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆ${count} æ¡è®°å½•ï¼‰`, parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ context å­å‘½ä»¤\næ”¯æŒ: on|off|show|del", parseMode: "html" });
          return;
        }

        /* ---------- æŠ˜å å¼€å…³ ---------- */
        if (subn === "collapse") {
          const a0 = (args[0] || "").toLowerCase();
          Store.data.collapse = a0 === "on";
          await Store.writeSoon();
          await msg.edit({ text: `âœ… æ¶ˆæ¯æŠ˜å : ${Store.data.collapse ? "å¼€å¯" : "å…³é—­"}`, parseMode: "html" });
          return;
        }

        /* ---------- Telegraph ---------- */
        if (subn === "telegraph") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "on") {
            Store.data.telegraph.enabled = true;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å¼€å¯ telegraph", parseMode: "html" });
            return;
          }
          if (a0 === "off") {
            Store.data.telegraph.enabled = false;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å…³é—­ telegraph", parseMode: "html" });
            return;
          }
          if (a0 === "limit") {
            const n = parseInt(args[1] || "0");
            Store.data.telegraph.limit = isFinite(n) ? n : 0;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… é˜ˆå€¼: ${Store.data.telegraph.limit}`, parseMode: "html" });
            return;
          }
          if (a0 === "list") {
            const list = Store.data.telegraph.posts.map((p, i) => `${i + 1}. <a href="${p.url}">${html(p.title)}</a> ${p.createdAt}`).join("\n") || "(ç©º)";
            await sendLong(msg, `ğŸ§¾ <b>Telegraph åˆ—è¡¨</b>\n\n${list}`);
            return;
          }
          if (a0 === "del") {
            const t = (args[1] || "").toLowerCase();
            if (t === "all") Store.data.telegraph.posts = [];
            else {
              const i = parseInt(args[1] || "0") - 1;
              if (i >= 0) Store.data.telegraph.posts.splice(i, 1);
            }
            await Store.writeSoon();
            await msg.edit({ text: "âœ… æ“ä½œå®Œæˆ", parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ telegraph å­å‘½ä»¤", parseMode: "html" });
          return;
        }

        /* ---------- éŸ³è‰²ç®¡ç† ---------- */
        if (subn === "voice") {
          const a0 = (args[0] || "").toLowerCase();
          if (!Store.data.voices) Store.data.voices = { gemini: "Kore", openai: "alloy" };
          if (a0 === "list") {
            const geminiList = GEMINI_VOICES.map((v, i) => `${i + 1}. ${v}`).join("\n");
            const openaiList = OPENAI_VOICES.map((v, i) => `${i + 1}. ${v}`).join("\n");
            const header = `ğŸ¤ <b>å¯ç”¨éŸ³è‰²åˆ—è¡¨</b>\n\n<b>å½“å‰é…ç½®:</b>\nGemini: <code>${Store.data.voices.gemini}</code>\nOpenAI: <code>${Store.data.voices.openai}</code>\n\n`;
            const collapsedContent = `<b>Gemini (${GEMINI_VOICES.length}ç§):</b>\n${geminiList}\n\n<b>OpenAI (${OPENAI_VOICES.length}ç§):</b>\n${openaiList}`;
            const txt = header + `<blockquote expandable>${collapsedContent}</blockquote>`;
            await sendLong(msg, txt);
            return;
          }
          if (a0 === "show") {
            const txt = `ğŸ¤ <b>å½“å‰éŸ³è‰²é…ç½®</b>\n\n<b>Gemini:</b> <code>${Store.data.voices.gemini}</code>\n<b>OpenAI:</b> <code>${Store.data.voices.openai}</code>`;
            await msg.edit({ text: txt, parseMode: "html" });
            return;
          }
          if (a0 === "gemini") {
            const voiceName = args[1];
            if (!voiceName) {
              await msg.edit({ text: `âŒ è¯·æŒ‡å®šéŸ³è‰²åç§°\nå½“å‰: <code>${Store.data.voices.gemini}</code>`, parseMode: "html" });
              return;
            }
            if (!GEMINI_VOICES.includes(voiceName as any)) {
              await msg.edit({ text: `âŒ æœªçŸ¥éŸ³è‰²: ${html(voiceName)}\nä½¿ç”¨ <code>ai voice list</code> æŸ¥çœ‹å¯ç”¨éŸ³è‰²`, parseMode: "html" });
              return;
            }
            Store.data.voices.gemini = voiceName;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²è®¾ç½® Gemini éŸ³è‰²: <code>${html(voiceName)}</code>`, parseMode: "html" });
            return;
          }
          if (a0 === "openai") {
            const voiceName = args[1];
            if (!voiceName) {
              await msg.edit({ text: `âŒ è¯·æŒ‡å®šéŸ³è‰²åç§°\nå½“å‰: <code>${Store.data.voices.openai}</code>`, parseMode: "html" });
              return;
            }
            if (!OPENAI_VOICES.includes(voiceName as any)) {
              await msg.edit({ text: `âŒ æœªçŸ¥éŸ³è‰²: ${html(voiceName)}\nä½¿ç”¨ <code>ai voice list</code> æŸ¥çœ‹å¯ç”¨éŸ³è‰²`, parseMode: "html" });
              return;
            }
            Store.data.voices.openai = voiceName;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²è®¾ç½® OpenAI éŸ³è‰²: <code>${html(voiceName)}</code>`, parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ voice å­å‘½ä»¤\næ”¯æŒ: list|show|gemini <éŸ³è‰²>|openai <éŸ³è‰²>", parseMode: "html" });
          return;
        }

        /* ---------- è¶…æ—¶è®¾ç½® ---------- */
        if (subn === "timeout") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "show" || !a0) {
            const current = Store.data.timeout || DEFAULT_TIMEOUT_MS;
            await msg.edit({ text: `â±ï¸ å½“å‰è¶…æ—¶æ—¶é—´: <code>${current / 1000}ç§’</code>`, parseMode: "html" });
            return;
          }
          if (a0 === "set") {
            const val = args[1];
            if (!val) {
              await msg.edit({ text: "âŒ è¯·æŒ‡å®šè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰\nä¾‹å¦‚: <code>ai timeout set 180</code> è®¾ç½®ä¸º180ç§’", parseMode: "html" });
              return;
            }
            const sec = parseInt(val);
            if (!isFinite(sec) || sec < 10 || sec > 600) {
              await msg.edit({ text: "âŒ è¶…æ—¶æ—¶é—´å¿…é¡»åœ¨ 10-600 ç§’ä¹‹é—´ï¼ˆæœ€å¤š10åˆ†é’Ÿï¼‰", parseMode: "html" });
              return;
            }
            Store.data.timeout = sec * 1000;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²è®¾ç½®è¶…æ—¶æ—¶é—´: <code>${sec}ç§’</code>`, parseMode: "html" });
            return;
          }
          if (a0 === "reset") {
            Store.data.timeout = DEFAULT_TIMEOUT_MS;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²é‡ç½®è¶…æ—¶æ—¶é—´ä¸ºé»˜è®¤å€¼: <code>${DEFAULT_TIMEOUT_MS / 1000}ç§’</code>`, parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ timeout å­å‘½ä»¤\næ”¯æŒ: show|set <ç§’>|reset", parseMode: "html" });
          return;
        }

        /* ---------- æœ€å¤§è¾“å‡º Token è®¾ç½® ---------- */
        if (subn === "maxtokens" || subn === "tokens" || subn === "maxtoken") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "show" || !a0) {
            const current = Store.data.maxTokens || DEFAULT_MAX_TOKENS;
            const approxChars = Math.floor(current / 2); // å¤§çº¦1 token = 0.5ä¸ªä¸­æ–‡å­—
            await msg.edit({ text: `ğŸ“ å½“å‰æœ€å¤§è¾“å‡º Token: <code>${current}</code>\nçº¦ç­‰äº <code>${approxChars}</code> ä¸ªä¸­æ–‡å­—\n\nğŸ’¡ ç”Ÿæˆè¶…é•¿æ–‡æœ¬æ—¶å»ºè®®åŒæ—¶å¢åŠ è¶…æ—¶æ—¶é—´`, parseMode: "html" });
            return;
          }
          if (a0 === "set") {
            const val = args[1];
            if (!val) {
              await msg.edit({ text: "âŒ è¯·æŒ‡å®šæœ€å¤§ token æ•°\nä¾‹å¦‚: <code>ai maxtokens set 32768</code> è®¾ç½®ä¸º32768", parseMode: "html" });
              return;
            }
            const num = parseInt(val);
            if (!isFinite(num) || num < 100 || num > 128000) {
              await msg.edit({ text: "âŒ Token æ•°å¿…é¡»åœ¨ 100-128000 ä¹‹é—´", parseMode: "html" });
              return;
            }
            Store.data.maxTokens = num;
            await Store.writeSoon();
            const approxChars = Math.floor(num / 2);
            await msg.edit({ text: `âœ… å·²è®¾ç½®æœ€å¤§è¾“å‡º Token: <code>${num}</code>\nçº¦ç­‰äº <code>${approxChars}</code> ä¸ªä¸­æ–‡å­—\n\nğŸ’¡ å»ºè®®åŒæ—¶è®¾ç½®è¶…æ—¶: <code>ai timeout set 300</code>`, parseMode: "html" });
            return;
          }
          if (a0 === "reset") {
            Store.data.maxTokens = DEFAULT_MAX_TOKENS;
            await Store.writeSoon();
            await msg.edit({ text: `âœ… å·²é‡ç½®æœ€å¤§è¾“å‡º Token ä¸ºé»˜è®¤å€¼: <code>${DEFAULT_MAX_TOKENS}</code>`, parseMode: "html" });
            return;
          }
          await msg.edit({ text: "âŒ æœªçŸ¥ maxtokens å­å‘½ä»¤\næ”¯æŒ: show|set <æ•°é‡>|reset", parseMode: "html" });
          return;
        }

        /* ---------- é“¾æ¥é¢„è§ˆå¼€å…³ ---------- */
        if (subn === "preview") {
          const a0 = (args[0] || "").toLowerCase();
          if (a0 === "on") {
            Store.data.linkPreview = true;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å¼€å¯é“¾æ¥é¢„è§ˆ", parseMode: "html" });
            return;
          }
          if (a0 === "off") {
            Store.data.linkPreview = false;
            await Store.writeSoon();
            await msg.edit({ text: "âœ… å·²å…³é—­é“¾æ¥é¢„è§ˆ", parseMode: "html" });
            return;
          }
          const current = Store.data.linkPreview !== false;
          await msg.edit({ text: `ğŸ”— é“¾æ¥é¢„è§ˆ: ${current ? "å¼€å¯" : "å…³é—­"}\n\nç”¨æ³•: <code>ai preview on|off</code>`, parseMode: "html" });
          return;
        }

        /* ---------- å¯¹è¯ / æœç´¢ ---------- */
        if (subn === "chat" || subn === "search" || !subn || isUnknownBareQuery) {
          const replyMsg = await msg.getReplyMessage();
          const isSearch = subn === "search";
          const plain = (((isUnknownBareQuery ? [sub, ...args] : args).join(" ") || "").trim());

          // ä»¿ç…§ temp/ai (10).ts çš„é€»è¾‘å¤„ç†ä¸Šä¸‹æ–‡
          let question = plain;
          let context = "";

          // å°è¯•æ™ºèƒ½è·å–åª’ä½“ï¼ˆæ”¯æŒå›¾ç‰‡ã€GIFã€Stickerç­‰ï¼‰
          // å¦‚æœæœ‰å›å¤æ¶ˆæ¯ï¼Œä¼˜å…ˆç”¨å›å¤æ¶ˆæ¯çš„åª’ä½“ï¼›å¦åˆ™å°è¯•å½“å‰æ¶ˆæ¯
          const mediaTarget = replyMsg && (replyMsg as any).media ? replyMsg : ((msg as any).media ? msg : null);
          const mediaData = mediaTarget ? await downloadMessageMediaAsData(mediaTarget) : null;
          const hasImage = !!mediaData;

          if (replyMsg) {
            // ä¼˜å…ˆä½¿ç”¨è¢«å¼•ç”¨çš„éƒ¨åˆ†ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ•´æ¡æ¶ˆæ¯
            context = extractQuoteOrReplyText(msg, replyMsg).trim();
            // å¦‚æœå›å¤çš„æ˜¯å›¾ç‰‡æ¶ˆæ¯ä½†æ²¡æœ‰æ–‡å­—å†…å®¹ï¼Œè¡¥å……è¯´æ˜
            if (!context && hasImage && mediaTarget === replyMsg) {
              context = "[ç”¨æˆ·å¼•ç”¨äº†ä¸€å¼ å›¾ç‰‡]";
            }
          }

          // å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥é—®é¢˜ï¼ˆåªå‘äº† .aiï¼‰ï¼Œåˆ™ç›´æ¥æŠŠå¼•ç”¨æ¶ˆæ¯å½“ä½œé—®é¢˜
          if (!question && context) {
            question = context;
            context = ""; // é¿å…é‡å¤ï¼Œæ—¢ç„¶å½“ä½œé—®é¢˜äº†å°±ä¸ç”¨ä½œä¸Šä¸‹æ–‡äº†
          }

          if (!question && !hasImage) {
            await msg.edit({ text: "âŒ è¯·è¾“å…¥å†…å®¹æˆ–å›å¤ä¸€æ¡æ¶ˆæ¯", parseMode: "html" });
            return;
          }

          // æ„å»ºæœ€ç»ˆå‘ç»™ AI çš„å†…å®¹ (Prompt)
          // æ ¼å¼ï¼š
          // å¼•ç”¨æ¶ˆæ¯:
          // [å†…å®¹]
          //
          // ç”¨æˆ·æ¶ˆæ¯:
          // [å†…å®¹]
          let q = question;
          if (context) {
            q = `å¼•ç”¨æ¶ˆæ¯:\n${context}\n\nç”¨æˆ·æ¶ˆæ¯:\n${question}`;
          }
          await msg.edit({ text: "ğŸ”„ å¤„ç†ä¸­...", parseMode: "html" });
          const pre = await preflight(isSearch ? "search" : "chat");
          if (!pre) return;
          const { m, p, compat } = pre;

          let content = "";
          let usedModel = m.model;
          if (hasImage && mediaData) {
            try {
              const b64 = mediaData.buffer.toString("base64");
              const processedPrompt = applyPresetPrompt(q || "æè¿°è¿™å¼ å›¾ç‰‡");
              // ä¼ å…¥ mime ä»¥æ”¯æŒä¸åŒæ ¼å¼ï¼ˆè™½ç„¶ç›®å‰è½¬ä¸º PNG æˆ–åŸæ ¼å¼ï¼‰
              content = await chatVision(p, compat, m.model, b64, processedPrompt, mediaData.mime);
            } catch (e: any) {
              await msg.edit({ text: `âŒ å¤„ç†å›¾ç‰‡å¤±è´¥ï¼š${html(mapError(e, "vision"))}`, parseMode: "html" });
              return;
            }
          } else {
            const res = await callChat(isSearch ? "search" : "chat", q, msg);
            content = res.content;
            usedModel = res.model;
          }

          // å¤„ç† AI å“åº”ï¼šæå–å†…åµŒå›¾ç‰‡ï¼Œæ¸…ç†æ€è€ƒæ ‡ç­¾
          const processed = processAIResponse(content);
          const replyToId = replyMsg?.id || 0;
          const footTxt = footer(usedModel, isSearch ? "with Search" : "");

          // å¦‚æœå“åº”ä¸­åŒ…å«å†…åµŒå›¾ç‰‡ï¼Œå…ˆå‘é€å›¾ç‰‡
          if (processed.images.length > 0) {
            for (const img of processed.images) {
              try {
                const buf = Buffer.from(img.data, "base64");
                const caption = img.alt ? `ğŸ–¼ï¸ ${html(img.alt)}` : `ğŸ–¼ï¸ AI ç”Ÿæˆçš„å›¾ç‰‡`;
                await sendImageFile(msg, buf, caption + footTxt, replyToId, img.mime);
              } catch {
                // å›¾ç‰‡å‘é€å¤±è´¥ï¼Œç»§ç»­å¤„ç†
              }
            }
            // å¦‚æœåªæœ‰å›¾ç‰‡æ²¡æœ‰å…¶ä»–æ–‡å­—å†…å®¹ï¼Œåˆ é™¤åŸæ¶ˆæ¯å¹¶è¿”å›
            const textContent = processed.text.replace(/\[å›¾ç‰‡\]/g, "").replace(/\[å›¾ç‰‡æ•°æ®\]/g, "").trim();
            if (!textContent || textContent.length < 10) {
              try { await msg.delete({ revoke: true }); } catch { /* å¿½ç•¥åˆ é™¤å¤±è´¥ */ }
              return;
            }
            // å¦‚æœè¿˜æœ‰æ–‡å­—å†…å®¹ï¼Œç»§ç»­å¤„ç†
            content = processed.text;
          } else {
            // å³ä½¿æ²¡æœ‰å›¾ç‰‡ä¹Ÿè¦æ¸…ç†æ€è€ƒæ ‡ç­¾
            content = processed.text;
          }

          const full = formatQA(q || "(å›¾ç‰‡)", content);

          if (Store.data.telegraph.enabled && Store.data.telegraph.limit > 0 && full.length > Store.data.telegraph.limit) {
            const tgContent = `Q: ${q || "(å›¾ç‰‡)"}\n\nA: ${content}`;
            const urls = await createTGPage("TeleBox AI", tgContent);
            if (urls.length > 0) {
              // ä¿å­˜å†å²è®°å½•ï¼ˆå€’åºæ’å…¥ï¼Œä¿æŒæ—¶é—´é¡ºåºï¼‰
              for (let i = urls.length - 1; i >= 0; i--) {
                Store.data.telegraph.posts.unshift({ title: (q || "å›¾ç‰‡").slice(0, 30) || "AI", url: urls[i], createdAt: nowISO() });
              }
              Store.data.telegraph.posts = Store.data.telegraph.posts.slice(0, 10);
              await Store.writeSoon();

              const links = urls.map((u, i) => {
                const num = urls.length > 1 ? (['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å'][i] || (i + 1)) : '';
                return `ğŸ”— <a href="${u}">ç‚¹æˆ‘é˜…è¯»å†…å®¹${num}</a>`;
              }).join("\n\n");
              const linkText = `ğŸ“° å†…å®¹è¾ƒé•¿ï¼ŒTelegraphè§‚æ„Ÿæ›´å¥½å–”:\n\n${links}`;

              const tgMsg = `Q:\n${q || "(å›¾ç‰‡)"}\n\nA:\n${linkText}\n${footTxt}`;
              try { await msg.delete({ revoke: true }); } catch { /* å¿½ç•¥åˆ é™¤å¤±è´¥ */ }
              if (msg.client) {
                await msg.client.sendMessage(msg.peerId, {
                  message: tgMsg,
                  parseMode: "html",
                  replyTo: replyToId || undefined,
                  linkPreview: Store.data.linkPreview !== false
                });
              }
              return;
            }
          }
          // å‘é€ç»“æœå¹¶åˆ é™¤åŸæ¶ˆæ¯
          try { await msg.delete({ revoke: true }); } catch { /* å¿½ç•¥åˆ é™¤å¤±è´¥ */ }
          const chunks = buildChunks(full, Store.data.collapse, footTxt);
          if (msg.client && chunks.length > 0) {
            const peer = msg.peerId;
            for (const chunk of chunks) {
              await msg.client.sendMessage(peer, {
                message: chunk,
                parseMode: "html",
                replyTo: replyToId || undefined
              });
            }
          }
          return;
        }

        /* ---------- ç”Ÿå›¾ ---------- */
        if (subn === "image") {
          const replyMsg = await msg.getReplyMessage();
          const fullText = (msg as any).text || (msg as any).message || "";
          const imagePromptMatch = fullText.match(/^[.\-\/!]ai\s+(?:image|img|i)\s+([\s\S]*)$/im);
          const userInput = (imagePromptMatch ? imagePromptMatch[1].trim() : args.join(" ").trim());
          const replyContent = extractQuoteOrReplyText(msg, replyMsg).trim();

          // æ£€æŸ¥æ˜¯å¦æœ‰å›å¤çš„å›¾ç‰‡ï¼ˆå›¾ç”Ÿå›¾æ¨¡å¼ï¼‰
          const mediaTarget = replyMsg && (replyMsg as any).media ? replyMsg : null;
          const mediaData = mediaTarget ? await downloadMessageMediaAsData(mediaTarget) : null;
          const hasSourceImage = !!mediaData;

          // ç»“åˆç”¨æˆ·è¾“å…¥å’Œå¼•ç”¨å†…å®¹
          let prm = "";
          if (userInput) {
            prm = userInput;
          } else if (replyContent && !hasSourceImage) {
            prm = replyContent;
          } else if (hasSourceImage) {
            prm = "è¯·åŸºäºè¿™å¼ å›¾ç‰‡è¿›è¡Œåˆ›ä½œ";
          }
          if (!prm && !hasSourceImage) {
            await msg.edit({ text: "âŒ è¯·è¾“å…¥æç¤ºè¯", parseMode: "html" });
            return;
          }
          const pre = await preflight("image");
          if (!pre) return;
          const { m, p, compat } = pre;
          const replyToId = replyMsg?.id || 0;

          await msg.edit({ text: hasSourceImage ? "ğŸ¨ å›¾ç”Ÿå›¾å¤„ç†ä¸­..." : "ğŸ¨ ç”Ÿæˆä¸­...", parseMode: "html" });

          if (compat === "openai") {
            // OpenAI å…¼å®¹æ¨¡å¼ï¼šæ”¯æŒå›¾ç”Ÿå›¾
            const sourceImage = hasSourceImage && mediaData ? {
              data: mediaData.buffer.toString("base64"),
              mime: mediaData.mime
            } : undefined;
            const b64 = await imageOpenAI(p, m.model, prm, sourceImage);
            if (!b64) {
              await msg.edit({ text: "âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šæœåŠ¡æ— æœ‰æ•ˆè¾“å‡º", parseMode: "html" });
              return;
            }
            const buf = Buffer.from(b64, "base64");
            const caption = hasSourceImage ? `ğŸ–¼ï¸ AI å›¾ç”Ÿå›¾` : `ğŸ–¼ï¸ AI ç”Ÿæˆå›¾ç‰‡`;
            await sendImageFile(msg, buf, caption + footer(m.model), replyToId);
            await msg.delete();
            return;
          } else if (compat === "gemini") {
            try {
              // å¦‚æœæœ‰æºå›¾ç‰‡ï¼Œä¼ å…¥å›¾ç”Ÿå›¾æ¨¡å¼
              const sourceImage = hasSourceImage && mediaData ? {
                data: mediaData.buffer.toString("base64"),
                mime: mediaData.mime
              } : undefined;
              const { image, text, mime } = await imageGemini(p, m.model, prm, sourceImage);
              if (image) {
                const caption = hasSourceImage ? `ğŸ–¼ï¸ AI å›¾ç”Ÿå›¾` : `ğŸ–¼ï¸ AI ç”Ÿæˆå›¾ç‰‡`;
                await sendImageFile(msg, image, caption + footer(m.model), replyToId, mime);
                await msg.delete();
                return;
              }
              if (text) {
                const textOut = formatQA(prm, text);
                await sendLongAuto(msg, textOut, replyToId, { collapse: Store.data.collapse }, footer(m.model));
                await msg.delete();
                return;
              }
              await msg.edit({ text: "âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šæœåŠ¡æ— æœ‰æ•ˆè¾“å‡º", parseMode: "html" });
              return;
            } catch (e: any) {
              await msg.edit({ text: `âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š${html(mapError(e, "image"))}`, parseMode: "html" });
              return;
            }
          } else {
            await msg.edit({ text: "âŒ å½“å‰æœåŠ¡å•†ä¸æ”¯æŒå›¾ç‰‡ç”ŸæˆåŠŸèƒ½", parseMode: "html" });
            return;
          }
        }

        /* ---------- è¯­éŸ³å›ç­” ---------- */
        if (subn === "audio" || subn === "searchaudio") {
          const replyMsg = await msg.getReplyMessage();
          const plain = (args.join(" ") || "").trim();

          // ä»¿ç…§ temp/ai (10).ts çš„é€»è¾‘å¤„ç†ä¸Šä¸‹æ–‡ (Voiceç‰ˆ)
          let question = plain;
          let context = "";

          if (replyMsg) {
            context = extractQuoteOrReplyText(msg, replyMsg).trim();
          }

          if (!question && context) {
            question = context;
            context = "";
          }

          if (!question) { await msg.edit({ text: "âŒ è¯·è¾“å…¥å†…å®¹æˆ–å›å¤ä¸€æ¡æ¶ˆæ¯", parseMode: "html" }); return; }

          // æ„å»º Prompt
          let q = question;
          if (context) {
            q = `å¼•ç”¨æ¶ˆæ¯:\n${context}\n\nç”¨æˆ·æ¶ˆæ¯:\n${question}`;
          }
          await msg.edit({ text: "ğŸ”„ å¤„ç†ä¸­...", parseMode: "html" });
          const res = await callChat(subn === "searchaudio" ? "search" : "chat", q, msg);
          await executeTTS(msg, res.content, replyMsg?.id || 0);
          return;
        }


        /* ---------- TTS ---------- */
        if (subn === "tts") {
          const replyMsg = await msg.getReplyMessage();
          const t = (args.join(" ") || "").trim() || extractQuoteOrReplyText(msg, replyMsg).trim();
          if (!t) { await msg.edit({ text: "âŒ è¯·è¾“å…¥æ–‡æœ¬", parseMode: "html" }); return; }
          await executeTTS(msg, t, replyMsg?.id || 0);
          return;
        }

        /* ---------- å…œåº• ---------- */
        await msg.edit({ text: "âŒ æœªçŸ¥å­å‘½ä»¤", parseMode: "html" });
        return;
      } catch (e: any) {
        await msg.edit({ text: `âŒ å‡ºé”™ï¼š${html(mapError(e, subn))}`, parseMode: "html" });
        return;
      }
    }
  };

  // èµ„æºæ¸…ç†æ–¹æ³• - é˜²æ­¢å†…å­˜æ³„æ¼
  async cleanup(): Promise<void> {
    try {
      // æ¸…ç† Store å†™å…¥å®šæ—¶å™¨
      if (Store._writeTimer) {
        clearTimeout(Store._writeTimer);
        Store._writeTimer = null;
      }
      // æ¸…ç†æ¨¡å‹åˆ·æ–°é˜²æŠ–å®šæ—¶å™¨
      if (refreshDebounceTimer) {
        clearTimeout(refreshDebounceTimer);
        refreshDebounceTimer = null;
      }
      // æ¸…ç†å…¼å®¹æ€§è§£æç¼“å­˜
      compatResolving.clear();
      // æ¸…ç† Anthropic ç‰ˆæœ¬ç¼“å­˜
      anthropicVersionCache.clear();
    } catch {
      // æ¸…ç†å¤±è´¥æ—¶é™é»˜å¤„ç†
    }
  }
}

export default new AiPlugin();
